\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Authors1_maskrcnn}
\citation{Authors2_BlendMask}
\citation{Authors3_MSCOCO}
\citation{Authors4_LVIS}
\citation{cityscapes}
\citation{wildDash}
\citation{Authors5_ResNet}
\citation{Authors6_SOLOv2}
\citation{Authors7_deepsnake}
\citation{Authors1_maskrcnn}
\citation{Authors2_BlendMask}
\citation{Authors6_SOLOv2}
\citation{Authors7_deepsnake}
\citation{Authors1_maskrcnn}
\citation{fasterRCNN}
\citation{fig1}
\citation{FPN}
\citation{Authors5_ResNet}
\citation{fig1}
\citation{FPN}
\citation{Authors5_ResNet}
\citation{Authors2_BlendMask}
\citation{fcos}
\citation{Authors2_BlendMask}
\citation{FPN}
\citation{Authors2_BlendMask}
\citation{FPN}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Related Work}{1}{section.2}\protected@file@percent }
\newlabel{sec:related-work}{{2}{1}{\hskip -1em.~Related Work}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}\hskip -1em.\nobreakspace  {}Stage approch}{1}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Mask R-CNN architecture. \textit  {Source:\nobreakspace  {}\cite  {fig1}, pag. 3.} The convolutional \textit  {backbones} (in the lower part of the figure) proposed in the paper are C4, C5 and FPN\nobreakspace  {}\cite  {FPN}. For \textit  {heads} (in the upper part of the figure) the backbone must include the 5th stage of ResNet\nobreakspace  {}\cite  {Authors5_ResNet}, "res5".}}{1}{figure.1}\protected@file@percent }
\newlabel{fig:mask_rcnn}{{1}{1}{Mask R-CNN architecture. \textit {Source:~\cite {fig1}, pag. 3.} The convolutional \textit {backbones} (in the lower part of the figure) proposed in the paper are C4, C5 and FPN~\cite {FPN}. For \textit {heads} (in the upper part of the figure) the backbone must include the 5th stage of ResNet~\cite {Authors5_ResNet}, "res5"}{figure.1}{}}
\citation{Authors6_SOLOv2}
\citation{solo}
\citation{Authors7_deepsnake}
\citation{cityscapes}
\citation{wildDash}
\citation{cityscapes}
\citation{cityscapes}
\citation{cityscapes}
\citation{wildDash}
\citation{wildDash}
\citation{imagenet}
\citation{wildDash}
\citation{wildDash}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces BlendMask architecture. \textit  {Source:\nobreakspace  {}\cite  {Authors2_BlendMask}, pag. 3.} The \textit  {bottom module} (to left) uses C4/C5 or FPN\nobreakspace  {}\cite  {FPN} and produces the bases. In the \textit  {top layer} (to right) a single convolution layer is added above the towers and this allows attention masks to be produced. The \textit  {blender module} (lower part of the figure), for each instance, combining bases linearly with the learned attention maps.}}{2}{figure.2}\protected@file@percent }
\newlabel{fig:blendmask}{{2}{2}{BlendMask architecture. \textit {Source:~\cite {Authors2_BlendMask}, pag. 3.} The \textit {bottom module} (to left) uses C4/C5 or FPN~\cite {FPN} and produces the bases. In the \textit {top layer} (to right) a single convolution layer is added above the towers and this allows attention masks to be produced. The \textit {blender module} (lower part of the figure), for each instance, combining bases linearly with the learned attention maps}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}\hskip -1em.\nobreakspace  {}Contour-based approach}{2}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Datasets}{2}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.\nobreakspace  {}Cityscapes}{2}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textit  {Cityscapes}\nobreakspace  {}\cite  {cityscapes} images: \textit  {gtFine} to left and \textit  {leftImg8} to right.}}{2}{figure.3}\protected@file@percent }
\newlabel{fig:image_gtfine}{{3}{2}{\textit {Cityscapes}~\cite {cityscapes} images: \textit {gtFine} to left and \textit {leftImg8} to right}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textit  {Cityscapes}: definitions of train dataset classes.}}{2}{figure.4}\protected@file@percent }
\newlabel{fig:class_definitions_city}{{4}{2}{\textit {Cityscapes}: definitions of train dataset classes}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\hskip -1em.\nobreakspace  {}WildDash}{2}{subsection.3.2}\protected@file@percent }
\newlabel{dataset_wd}{{3.2}{2}{\hskip -1em.~WildDash}{subsection.3.2}{}}
\citation{Authors1_maskrcnn}
\citation{Authors2_BlendMask}
\citation{Authors1_maskrcnn}
\citation{Authors2_BlendMask}
\citation{Authors1_maskrcnn}
\citation{Authors2_BlendMask}
\citation{protonet}
\citation{Authors5_ResNet}
\citation{resxt}
\citation{Authors1_maskrcnn}
\citation{resxt}
\citation{Authors5_ResNet}
\citation{resnet101_img}
\citation{resnet101_img}
\citation{Authors5_ResNet}
\citation{Authors1_maskrcnn}
\citation{Authors2_BlendMask}
\citation{FPN}
\citation{Authors1_maskrcnn}
\citation{Authors2_BlendMask}
\citation{FPN}
\citation{FPN}
\citation{protonet}
\citation{protonet}
\citation{protonet}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textit  {WildDash}\nobreakspace  {}\cite  {wildDash} images: \textit  {rain scenario} to left and \textit  {road in the desert} to right.}}{3}{figure.5}\protected@file@percent }
\newlabel{fig:image_wd}{{5}{3}{\textit {WildDash}~\cite {wildDash} images: \textit {rain scenario} to left and \textit {road in the desert} to right}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textit  {WildDash}: definitions of train dataset classes.}}{3}{figure.6}\protected@file@percent }
\newlabel{fig:class_definitions_wd}{{6}{3}{\textit {WildDash}: definitions of train dataset classes}{figure.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Method}{3}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.\nobreakspace  {}Architecture}{3}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}ResNet 101}{3}{subsubsection.4.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The structure of the ResNet 101. \textit  {Source: \nobreakspace  {}\cite  {resnet101_img}, pag. 6.} The figure shows Resnet 101. It uses skip connections, i.e. arcs over each block, to solve the problems associated with gradient computation.}}{3}{figure.7}\protected@file@percent }
\newlabel{fig:resnet101}{{7}{3}{The structure of the ResNet 101. \textit {Source: ~\cite {resnet101_img}, pag. 6.} The figure shows Resnet 101. It uses skip connections, i.e. arcs over each block, to solve the problems associated with gradient computation}{figure.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Feature Pyramid Network}{3}{subsubsection.4.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces FPN for object segment proposals. \textit  {Source:\nobreakspace  {}\cite  {FPN}, pag. 8.} Each level of the pyramid tries to detect all instances present in an image. A features map/bases are produced for each of these layers, and each will produce a mask. The latter will be combined into a single final mask.}}{3}{figure.8}\protected@file@percent }
\newlabel{fig:FPN}{{8}{3}{FPN for object segment proposals. \textit {Source:~\cite {FPN}, pag. 8.} Each level of the pyramid tries to detect all instances present in an image. A features map/bases are produced for each of these layers, and each will produce a mask. The latter will be combined into a single final mask}{figure.8}{}}
\citation{Authors1_maskrcnn}
\citation{Authors2_BlendMask}
\citation{Authors1_maskrcnn}
\citation{Authors8_semanticloss}
\citation{Authors2_BlendMask}
\citation{Authors2_BlendMask}
\citation{cityscapes}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}ProtoNet decoder}{4}{subsubsection.4.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Protonet architecture. \textit  {Source:\nobreakspace  {}\cite  {protonet}, pag. 4.} The labels denote feature size and channels for an image size of 550 $\times $ 550. Arrows indicate 3 $\times $ 3 conv layers, except for the final conv which is 1 $\times $ 1. The increase in size is an upsample followed by a conv. As can be seen, the last layer has as many channels as k prototypes.}}{4}{figure.9}\protected@file@percent }
\newlabel{fig:protonet}{{9}{4}{Protonet architecture. \textit {Source:~\cite {protonet}, pag. 4.} The labels denote feature size and channels for an image size of 550 $\times $ 550. Arrows indicate 3 $\times $ 3 conv layers, except for the final conv which is 1 $\times $ 1. The increase in size is an upsample followed by a conv. As can be seen, the last layer has as many channels as k prototypes}{figure.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.\nobreakspace  {}Hyperparameters configuration}{4}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}\hskip -1em.\nobreakspace  {}Loss function}{4}{subsection.4.3}\protected@file@percent }
\newlabel{loss_mask}{{1}{4}{\hskip -1em.~Loss function}{equation.4.1}{}}
\newlabel{Loss_semantic}{{2}{4}{\hskip -1em.~Loss function}{equation.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}\hskip -1em.\nobreakspace  {}Evalutation}{4}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Metrics}{4}{subsubsection.4.4.1}\protected@file@percent }
\newlabel{AP}{{3}{4}{Metrics}{equation.4.3}{}}
\citation{Authors1_maskrcnn}
\citation{FPN}
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.\nobreakspace  {}Experiments}{5}{section.5}\protected@file@percent }
\newlabel{sec:experiments}{{5}{5}{\hskip -1em.~Experiments}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}\hskip -1em.\nobreakspace  {}Backbone}{5}{subsection.5.1}\protected@file@percent }
\newlabel{experiments:second_trial}{{5.1}{5}{\hskip -1em.~Backbone}{subsection.5.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Experiments on \textit  {backbone} Mask R-CNN}}{5}{table.1}\protected@file@percent }
\newlabel{tab1}{{1}{5}{Experiments on \textit {backbone} Mask R-CNN}{table.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Experiments on \textit  {backbone} BlendMask.}}{5}{table.2}\protected@file@percent }
\newlabel{tab2}{{2}{5}{Experiments on \textit {backbone} BlendMask}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}\hskip -1em.\nobreakspace  {}Frozen layers}{5}{subsection.5.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Experiments on \textit  {frozen layers} Mask R-CNN.}}{5}{table.3}\protected@file@percent }
\newlabel{tab3}{{3}{5}{Experiments on \textit {frozen layers} Mask R-CNN}{table.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Experiments on \textit  {frozen layers} BlendMask.}}{5}{table.4}\protected@file@percent }
\newlabel{tab4}{{4}{5}{Experiments on \textit {frozen layers} BlendMask}{table.4}{}}
\citation{Authors2_BlendMask}
\citation{Authors2_BlendMask}
\citation{Authors2_BlendMask}
\citation{Authors2_BlendMask}
\citation{Authors2_BlendMask}
\citation{Authors2_BlendMask}
\citation{Authors2_BlendMask}
\citation{Authors2_BlendMask}
\citation{Authors2_BlendMask}
\citation{Authors1_maskrcnn}
\citation{Authors2_BlendMask}
\citation{Authors6_SOLOv2}
\citation{Authors6_SOLOv2}
\citation{Authors6_SOLOv2}
\citation{Authors6_SOLOv2}
\citation{Authors7_deepsnake}
\citation{Authors7_deepsnake}
\citation{Authors7_deepsnake}
\bibcite{Authors1_maskrcnn}{1}
\bibcite{Authors2_BlendMask}{2}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}\hskip -1em.\nobreakspace  {}Ideal models}{6}{subsection.5.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Results \textit  {ideal models}: the architecture is ResNet-101-FPN with freeze at 2nd. In brackets are the improvements of \textit  {BlendMask ideal model} compared to \textit  {Mask R-CNN ideal model}, and follow the improvements in the reference paper\nobreakspace  {}\cite  {Authors2_BlendMask}, when exist.}}{6}{table.5}\protected@file@percent }
\newlabel{mytable_ideal_models}{{5}{6}{Results \textit {ideal models}: the architecture is ResNet-101-FPN with freeze at 2nd. In brackets are the improvements of \textit {BlendMask ideal model} compared to \textit {Mask R-CNN ideal model}, and follow the improvements in the reference paper~\cite {Authors2_BlendMask}, when exist}{table.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces \textit  {Models ideal results}: Mask image (to left) and Blend image (to right). First row is \textit  {Cityscapes} dataset and second row is \textit  {WildDash} dataset. In the figure we see that Mask R-CNN tends to have a higher instance recognition score than BlendMask, despite having a lower AP. This is because it is more confident than BlendMask, but this also leads it to be more penalised.}}{6}{figure.10}\protected@file@percent }
\newlabel{fig:result_model_ideal}{{10}{6}{\textit {Models ideal results}: Mask image (to left) and Blend image (to right). First row is \textit {Cityscapes} dataset and second row is \textit {WildDash} dataset. In the figure we see that Mask R-CNN tends to have a higher instance recognition score than BlendMask, despite having a lower AP. This is because it is more confident than BlendMask, but this also leads it to be more penalised}{figure.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}\hskip -1em.\nobreakspace  {}Conclusion}{6}{section.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Comparison between SOLOv2 and other stage approaches. \textit  {Source:\nobreakspace  {}\cite  {Authors6_SOLOv2}, pag. 2.} Mask R-CNN is box base two-stage approach, the others are box-free or anchor box-free one-stage approach.}}{6}{figure.11}\protected@file@percent }
\newlabel{fig:conclusionSOLOv2}{{11}{6}{Comparison between SOLOv2 and other stage approaches. \textit {Source:~\cite {Authors6_SOLOv2}, pag. 2.} Mask R-CNN is box base two-stage approach, the others are box-free or anchor box-free one-stage approach}{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Results on \textit  {Cityscapes} val (AP [val] column) and test (remaining columns) sets. \textit  {Source:\nobreakspace  {}\cite  {Authors7_deepsnake}, pag. 7.}}}{6}{figure.12}\protected@file@percent }
\newlabel{fig:conclusiondeepsnake}{{12}{6}{Results on \textit {Cityscapes} val (AP [val] column) and test (remaining columns) sets. \textit {Source:~\cite {Authors7_deepsnake}, pag. 7.}}{figure.12}{}}
\bibcite{Authors3_MSCOCO}{3}
\bibcite{Authors4_LVIS}{4}
\bibcite{cityscapes}{5}
\bibcite{wildDash}{6}
\bibcite{Authors5_ResNet}{7}
\bibcite{Authors6_SOLOv2}{8}
\bibcite{Authors7_deepsnake}{9}
\bibcite{fasterRCNN}{10}
\bibcite{fig1}{11}
\bibcite{FPN}{12}
\bibcite{fcos}{13}
\bibcite{solo}{14}
\bibcite{imagenet}{15}
\bibcite{resnet101_img}{16}
\bibcite{resxt}{17}
\bibcite{protonet}{18}
\bibcite{Authors8_semanticloss}{19}
\bibcite{fine-tuning}{20}
\bibcite{tensormask}{21}
\bibcite{yolact}{22}
\bibcite{polarmask}{23}
