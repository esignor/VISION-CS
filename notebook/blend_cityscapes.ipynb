{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"blend_cityscapes.ipynb","provenance":[],"authorship_tag":"ABX9TyNdw/JQ5nsygbNJ7yQtRl0p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Blend Mask (Cityscapes)"],"metadata":{"id":"lD3DyscQHlX7"}},{"cell_type":"markdown","source":["**(Esegui tutto)**"],"metadata":{"id":"Utz2QGgfHv8z"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"m2q1qug1HgAa"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install pyyaml==5.1\n","\n","# Cerchiamo la versione che porti il match perfetto tra le librerie\n","import torch\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","\n","from IPython.display import Image, clear_output\n","\n","!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n","\n","clear_output()"],"metadata":{"id":"tCyGEC35Hzo1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cloning AdelaiDet\n","%cd /content\n","!git clone https://github.com/aim-uofa/AdelaiDet.git\n","%cd AdelaiDet/\n","!python setup.py build develop\n","\n","clear_output()"],"metadata":{"id":"X4ZXdWbXIzS_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Some basic setup:\n","import adet\n","# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import os, json, cv2, random\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","from detectron2.engine import DefaultPredictor\n","from adet.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog"],"metadata":{"id":"ORey8_CpI1nn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget -O blendmask_r101_3x.pth https://cloudstor.aarnet.edu.au/plus/s/e4fXrliAcMtyEBy/download\n","\n","clear_output()"],"metadata":{"id":"IboIMYiHI3zC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Scelta del modello**"],"metadata":{"id":"TIFgiE0qK8aj"}},{"cell_type":"code","source":["model_BM_ResNet_101 = \"configs/BlendMask/R_101_3x.yaml\"\n","weight_BM_ResNet_101 = \"blendmask_r101_3x.pth\""],"metadata":{"id":"FOt2cFz5I5w3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python -m pip install cityscapesscripts\n","\n","clear_output()"],"metadata":{"id":"HPY73i95I-Mc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import functools\n","import json\n","import logging\n","import multiprocessing as mp\n","import numpy as np\n","import os\n","from itertools import chain\n","import pycocotools.mask as mask_util\n","from PIL import Image\n","\n","from detectron2.structures import BoxMode\n","from detectron2.utils.comm import get_world_size\n","from detectron2.utils.file_io import PathManager\n","from detectron2.utils.logger import setup_logger\n","\n","from cityscapesscripts.helpers.labels import labels\n","from cityscapesscripts.helpers.labels import id2label, name2label\n","\n","try:\n","    import cv2\n","except ImportError:\n","    # OpenCV is an optional dependency at the moment\n","    pass\n","\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","def _get_cityscapes_files(image_dir, gt_dir):\n","    files = []\n","    # scan through the directory\n","    cities = PathManager.ls(image_dir)\n","    logger.info(f\"{len(cities)} cities found in '{image_dir}'.\")\n","    for city in cities:\n","        city_img_dir = os.path.join(image_dir, city)\n","        city_gt_dir = os.path.join(gt_dir, city)\n","        for basename in PathManager.ls(city_img_dir):\n","            image_file = os.path.join(city_img_dir, basename)\n","\n","            suffix = \"leftImg8bit.png\"\n","            assert basename.endswith(suffix), basename\n","            basename = basename[: -len(suffix)]\n","\n","            instance_file = os.path.join(city_gt_dir, basename + \"gtFine_instanceIds.png\")\n","            label_file = os.path.join(city_gt_dir, basename + \"gtFine_labelIds.png\")\n","            json_file = os.path.join(city_gt_dir, basename + \"gtFine_polygons.json\")\n","\n","            files.append((image_file, instance_file, label_file, json_file))\n","    assert len(files), \"No images found in {}\".format(image_dir)\n","    for f in files[0]:\n","        assert PathManager.isfile(f), f\n","    return files\n","\n","\n","def load_cityscapes_instances(image_dir, gt_dir, from_json=True, to_polygons=True):\n","    \"\"\"\n","    Args:\n","        image_dir (str): path to the raw dataset. e.g., \"~/cityscapes/leftImg8bit/train\".\n","        gt_dir (str): path to the raw annotations. e.g., \"~/cityscapes/gtFine/train\".\n","        from_json (bool): whether to read annotations from the raw json file or the png files.\n","        to_polygons (bool): whether to represent the segmentation as polygons\n","            (COCO's format) instead of masks (cityscapes's format).\n","\n","    Returns:\n","        list[dict]: a list of dicts in Detectron2 standard format. (See\n","        `Using Custom Datasets </tutorials/datasets.html>`_ )\n","    \"\"\"\n","    if from_json:\n","        assert to_polygons, (\n","            \"Cityscapes's json annotations are in polygon format. \"\n","            \"Converting to mask format is not supported now.\"\n","        )\n","    files = _get_cityscapes_files(image_dir, gt_dir)\n","\n","    logger.info(\"Preprocessing cityscapes annotations ...\")\n","    # This is still not fast: all workers will execute duplicate works and will\n","    # take up to 10m on a 8GPU server.\n","    pool = mp.Pool(processes=max(mp.cpu_count() // get_world_size() // 2, 4))\n","\n","    ret = pool.map(\n","        functools.partial(_cityscapes_files_to_dict, from_json=from_json, to_polygons=to_polygons),\n","        files,\n","    )\n","    logger.info(\"Loaded {} images from {}\".format(len(ret), image_dir))\n","\n","    # Map cityscape ids to contiguous ids\n","    from cityscapesscripts.helpers.labels import labels\n","\n","    labels = [l for l in labels if l.hasInstances and not l.ignoreInEval]\n","    dataset_id_to_contiguous_id = {l.id: idx for idx, l in enumerate(labels)}\n","    for dict_per_image in ret:\n","        for anno in dict_per_image[\"annotations\"]:\n","            anno[\"category_id\"] = dataset_id_to_contiguous_id[anno[\"category_id\"]]\n","    return ret\n","\n","\n","def load_cityscapes_semantic(image_dir, gt_dir):\n","    \"\"\"\n","    Args:\n","        image_dir (str): path to the raw dataset. e.g., \"~/cityscapes/leftImg8bit/train\".\n","        gt_dir (str): path to the raw annotations. e.g., \"~/cityscapes/gtFine/train\".\n","\n","    Returns:\n","        list[dict]: a list of dict, each has \"file_name\" and\n","            \"sem_seg_file_name\".\n","    \"\"\"\n","    ret = []\n","    # gt_dir is small and contain many small files. make sense to fetch to local first\n","    gt_dir = PathManager.get_local_path(gt_dir)\n","    for image_file, _, label_file, json_file in _get_cityscapes_files(image_dir, gt_dir):\n","        label_file = label_file.replace(\"labelIds\", \"labelTrainIds\")\n","\n","        with PathManager.open(json_file, \"r\") as f:\n","            jsonobj = json.load(f)\n","        ret.append(\n","            {\n","                \"file_name\": image_file,\n","                \"sem_seg_file_name\": label_file,\n","                \"height\": jsonobj[\"imgHeight\"],\n","                \"width\": jsonobj[\"imgWidth\"],\n","            }\n","        )\n","    assert len(ret), f\"No images found in {image_dir}!\"\n","    assert PathManager.isfile(\n","        ret[0][\"sem_seg_file_name\"]\n","    ), \"Please generate labelTrainIds.png with cityscapesscripts/preparation/createTrainIdLabelImgs.py\"  # noqa\n","    return ret\n","\n","\n","def _cityscapes_files_to_dict(files, from_json, to_polygons):\n","    \"\"\"\n","    Parse cityscapes annotation files to a instance segmentation dataset dict.\n","\n","    Args:\n","        files (tuple): consists of (image_file, instance_id_file, label_id_file, json_file)\n","        from_json (bool): whether to read annotations from the raw json file or the png files.\n","        to_polygons (bool): whether to represent the segmentation as polygons\n","            (COCO's format) instead of masks (cityscapes's format).\n","\n","    Returns:\n","        A dict in Detectron2 Dataset format.\n","    \"\"\"\n","    from cityscapesscripts.helpers.labels import id2label, name2label\n","\n","    image_file, instance_id_file, _, json_file = files\n","\n","    annos = []\n","\n","    if from_json:\n","        from shapely.geometry import MultiPolygon, Polygon\n","\n","        with PathManager.open(json_file, \"r\") as f:\n","            jsonobj = json.load(f)\n","        ret = {\n","            \"file_name\": image_file,\n","            \"image_id\": os.path.basename(image_file),\n","            \"height\": jsonobj[\"imgHeight\"],\n","            \"width\": jsonobj[\"imgWidth\"],\n","        }\n","\n","        # `polygons_union` contains the union of all valid polygons.\n","        polygons_union = Polygon()\n","\n","        # CityscapesScripts draw the polygons in sequential order\n","        # and each polygon *overwrites* existing ones. See\n","        # (https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/preparation/json2instanceImg.py) # noqa\n","        # We use reverse order, and each polygon *avoids* early ones.\n","        # This will resolve the ploygon overlaps in the same way as CityscapesScripts.\n","        for obj in jsonobj[\"objects\"][::-1]:\n","            if \"deleted\" in obj:  # cityscapes data format specific\n","                continue\n","            label_name = obj[\"label\"]\n","\n","            try:\n","                label = name2label[label_name]\n","            except KeyError:\n","                if label_name.endswith(\"group\"):  # crowd area\n","                    label = name2label[label_name[: -len(\"group\")]]\n","                else:\n","                    raise\n","            if label.id < 0:  # cityscapes data format\n","                continue\n","\n","            # Cityscapes's raw annotations uses integer coordinates\n","            # Therefore +0.5 here\n","            poly_coord = np.asarray(obj[\"polygon\"], dtype=\"f4\") + 0.5\n","            # CityscapesScript uses PIL.ImageDraw.polygon to rasterize\n","            # polygons for evaluation. This function operates in integer space\n","            # and draws each pixel whose center falls into the polygon.\n","            # Therefore it draws a polygon which is 0.5 \"fatter\" in expectation.\n","            # We therefore dilate the input polygon by 0.5 as our input.\n","            poly = Polygon(poly_coord).buffer(0.5, resolution=4)\n","\n","            if not label.hasInstances or label.ignoreInEval:\n","                # even if we won't store the polygon it still contributes to overlaps resolution\n","                polygons_union = polygons_union.union(poly)\n","                continue\n","\n","            # Take non-overlapping part of the polygon\n","            poly_wo_overlaps = poly.difference(polygons_union)\n","            if poly_wo_overlaps.is_empty:\n","                continue\n","            polygons_union = polygons_union.union(poly)\n","\n","            anno = {}\n","            anno[\"iscrowd\"] = label_name.endswith(\"group\")\n","            anno[\"category_id\"] = label.id\n","\n","            if isinstance(poly_wo_overlaps, Polygon):\n","                poly_list = [poly_wo_overlaps]\n","            elif isinstance(poly_wo_overlaps, MultiPolygon):\n","                poly_list = poly_wo_overlaps.geoms\n","            else:\n","                raise NotImplementedError(\"Unknown geometric structure {}\".format(poly_wo_overlaps))\n","\n","            poly_coord = []\n","            for poly_el in poly_list:\n","                # COCO API can work only with exterior boundaries now, hence we store only them.\n","                # TODO: store both exterior and interior boundaries once other parts of the\n","                # codebase support holes in polygons.\n","                poly_coord.append(list(chain(*poly_el.exterior.coords)))\n","            anno[\"segmentation\"] = poly_coord\n","            (xmin, ymin, xmax, ymax) = poly_wo_overlaps.bounds\n","\n","            anno[\"bbox\"] = (xmin, ymin, xmax, ymax)\n","            anno[\"bbox_mode\"] = BoxMode.XYXY_ABS\n","\n","            annos.append(anno)\n","    else:\n","        # See also the official annotation parsing scripts at\n","        # https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/evaluation/instances2dict.py  # noqa\n","        with PathManager.open(instance_id_file, \"rb\") as f:\n","            inst_image = np.asarray(Image.open(f), order=\"F\")\n","        # ids < 24 are stuff labels (filtering them first is about 5% faster)\n","        flattened_ids = np.unique(inst_image[inst_image >= 24])\n","\n","        ret = {\n","            \"file_name\": image_file,\n","            \"image_id\": os.path.basename(image_file),\n","            \"height\": inst_image.shape[0],\n","            \"width\": inst_image.shape[1],\n","        }\n","\n","        for instance_id in flattened_ids:\n","            # For non-crowd annotations, instance_id // 1000 is the label_id\n","            # Crowd annotations have <1000 instance ids\n","            label_id = instance_id // 1000 if instance_id >= 1000 else instance_id\n","            label = id2label[label_id]\n","            if not label.hasInstances or label.ignoreInEval:\n","                continue\n","\n","            anno = {}\n","            anno[\"iscrowd\"] = instance_id < 1000\n","            anno[\"category_id\"] = label.id\n","\n","            mask = np.asarray(inst_image == instance_id, dtype=np.uint8, order=\"F\")\n","\n","            inds = np.nonzero(mask)\n","            ymin, ymax = inds[0].min(), inds[0].max()\n","            xmin, xmax = inds[1].min(), inds[1].max()\n","            anno[\"bbox\"] = (xmin, ymin, xmax, ymax)\n","            if xmax <= xmin or ymax <= ymin:\n","                continue\n","            anno[\"bbox_mode\"] = BoxMode.XYXY_ABS\n","            if to_polygons:\n","                # This conversion comes from D4809743 and D5171122,\n","                # when Mask-RCNN was first developed.\n","                contours = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[\n","                    -2\n","                ]\n","                polygons = [c.reshape(-1).tolist() for c in contours if len(c) >= 3]\n","                # opencv's can produce invalid polygons\n","                if len(polygons) == 0:\n","                    continue\n","                anno[\"segmentation\"] = polygons\n","            else:\n","                anno[\"segmentation\"] = mask_util.encode(mask[:, :, None])[0]\n","            annos.append(anno)\n","    ret[\"annotations\"] = annos\n","    return ret"],"metadata":{"id":"f-hHKQo1JB7B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cityscapes_classes = [k.name for k in labels if k.hasInstances and not k.ignoreInEval]\n","\n","image_dir = \"/content/drive/MyDrive/datasets/cityscapes/leftImg8bit/\"\n","gt_dir = \"/content/drive/MyDrive/datasets/cityscapes/gtFine/\"\n","\n","for d in [\"train\"]:\n","  DatasetCatalog.register(\"cityscapes_\" + d, lambda x=image_dir+d, y=gt_dir+d: load_cityscapes_instances(x, y))\n","  MetadataCatalog.get(\"cityscapes_\" + d).set(thing_classes=cityscapes_classes, evaluator_type=\"coco\")\n","\n","for d in [\"val\"]:\n","  DatasetCatalog.register(\"cityscapes_\" + d, lambda x=image_dir+d, y=gt_dir+d: load_cityscapes_instances(x, y))\n","  MetadataCatalog.get(\"cityscapes_\" + d).set(thing_classes=cityscapes_classes, evaluator_type=\"coco\")\n","\n","for d in [\"test\"]:\n","  DatasetCatalog.register(\"cityscapes_\" + d, lambda x=image_dir+d, y=gt_dir+d: load_cityscapes_instances(x, y))\n","  MetadataCatalog.get(\"cityscapes_\" + d).set(thing_classes=cityscapes_classes, evaluator_type=\"coco\")"],"metadata":{"id":"J9FG2TWCJISH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from detectron2.engine import DefaultTrainer\n","\n","\n","cfg = get_cfg()\n","cfg.merge_from_file(model_BM_ResNet_101)\n","cfg.DATASETS.TRAIN = (\"cityscapes_train\",)\n","cfg.DATASETS.TEST = ()\n","cfg.MODEL.WEIGHTS = weight_BM_ResNet_101 \n","\n","\n","cfg.MODEL.BASIS_MODULE.NORM = \"BN\" # Not SyncBN because we have only 1 GPU and 1 machine, otherwise there is a problem with init groups of process\n","cfg.MODEL.BASIS_MODULE.LOSS_ON = False\n","\n","\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n","cfg.SOLVER.IMS_PER_BATCH = 4 #su mask usiamo 1... \n","cfg.SOLVER.MAX_ITER = 2000\n","cfg.SOLVER.STEPS = (1500,)\n","\n","# Classi di Cityscapes\n","#cfg.MODEL.ROI_HEADS.NUM_CLASSES = 8\n","cfg.MODEL.BASIS_MODULE.NUM_CLASSES = 8 # of BlendMask\n","\n","\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","trainer = DefaultTrainer(cfg)\n","trainer.resume_or_load(resume=False)\n","trainer.train()"],"metadata":{"id":"CTBxmgluJLFc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n","predictor = DefaultPredictor(cfg)"],"metadata":{"id":"DdSdKpqYNezF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","from detectron2.data import build_detection_test_loader\n","evaluator = COCOEvaluator(\"cityscapes_val\", cfg, False, output_dir=\"./output\")\n","val_loader = build_detection_test_loader(cfg, \"cityscapes_val\")\n","print(inference_on_dataset(predictor.model, val_loader, evaluator))"],"metadata":{"id":"HCxlhN-zNnWj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Stampa immagini**"],"metadata":{"id":"QiATS8unOAkC"}},{"cell_type":"code","source":["def print_inference(img_path, predictor):\n","  img = cv2.imread(img_path)\n","  outputs = predictor(img)\n","  v = Visualizer(img[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=0.5)\n","  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","  cv2_imshow(out.get_image()[:, :, ::-1])\n","\n","\n","# Esempio di utilizzo\n","print_inference(\"/content/drive/MyDrive/datasets/wd_public_02/images_test/tk0000_100000.jpg\", predictor)"],"metadata":{"id":"Ork0n355N8t7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%load_ext tensorboard\n","%tensorboard --logdir output"],"metadata":{"id":"9lD3LbyAN_yk"},"execution_count":null,"outputs":[]}]}