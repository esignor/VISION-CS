{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"blend_cityscapes.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Blend Mask (Cityscapes)"],"metadata":{"id":"lD3DyscQHlX7"}},{"cell_type":"markdown","source":["**(Esegui tutto)**"],"metadata":{"id":"Utz2QGgfHv8z"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"m2q1qug1HgAa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644156606100,"user_tz":-60,"elapsed":14553,"user":{"displayName":"muchsb 2021","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioRvCcJyMu2pLImQLAH9SrtPIxQR-65c4Rc0Lq=s64","userId":"04872446583146860130"}},"outputId":"721c8ceb-2de7-4ccb-9d84-7a5fea2bacc1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install pyyaml==5.1\n","\n","# Cerchiamo la versione che porti il match perfetto tra le librerie\n","import torch\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","\n","from IPython.display import Image, clear_output\n","\n","!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n","\n","clear_output()"],"metadata":{"id":"tCyGEC35Hzo1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cloning AdelaiDet\n","%cd /content\n","!git clone https://github.com/aim-uofa/AdelaiDet.git\n","%cd AdelaiDet/\n","!python setup.py build develop\n","\n","clear_output()"],"metadata":{"id":"X4ZXdWbXIzS_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Some basic setup:\n","import adet\n","# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import os, json, cv2, random\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","from detectron2.engine import DefaultPredictor\n","from adet.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog"],"metadata":{"id":"ORey8_CpI1nn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget -O blendmask_r101_3x.pth https://cloudstor.aarnet.edu.au/plus/s/e4fXrliAcMtyEBy/download\n","\n","clear_output()"],"metadata":{"id":"IboIMYiHI3zC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Scelta del modello**"],"metadata":{"id":"TIFgiE0qK8aj"}},{"cell_type":"code","source":["model_BM_ResNet_101 = \"configs/BlendMask/R_101_3x.yaml\"\n","weight_BM_ResNet_101 = \"blendmask_r101_3x.pth\""],"metadata":{"id":"FOt2cFz5I5w3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python -m pip install cityscapesscripts\n","\n","clear_output()"],"metadata":{"id":"HPY73i95I-Mc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import functools\n","import json\n","import logging\n","import multiprocessing as mp\n","import numpy as np\n","import os\n","from itertools import chain\n","import pycocotools.mask as mask_util\n","from PIL import Image\n","\n","from detectron2.structures import BoxMode\n","from detectron2.utils.comm import get_world_size\n","from detectron2.utils.file_io import PathManager\n","from detectron2.utils.logger import setup_logger\n","\n","from cityscapesscripts.helpers.labels import labels\n","from cityscapesscripts.helpers.labels import id2label, name2label\n","\n","try:\n","    import cv2\n","except ImportError:\n","    # OpenCV is an optional dependency at the moment\n","    pass\n","\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","def _get_cityscapes_files(image_dir, gt_dir):\n","    files = []\n","    # scan through the directory\n","    cities = PathManager.ls(image_dir)\n","    logger.info(f\"{len(cities)} cities found in '{image_dir}'.\")\n","    for city in cities:\n","        city_img_dir = os.path.join(image_dir, city)\n","        city_gt_dir = os.path.join(gt_dir, city)\n","        for basename in PathManager.ls(city_img_dir):\n","            image_file = os.path.join(city_img_dir, basename)\n","\n","            suffix = \"leftImg8bit.png\"\n","            assert basename.endswith(suffix), basename\n","            basename = basename[: -len(suffix)]\n","\n","            instance_file = os.path.join(city_gt_dir, basename + \"gtFine_instanceIds.png\")\n","            label_file = os.path.join(city_gt_dir, basename + \"gtFine_labelIds.png\")\n","            json_file = os.path.join(city_gt_dir, basename + \"gtFine_polygons.json\")\n","\n","            files.append((image_file, instance_file, label_file, json_file))\n","    assert len(files), \"No images found in {}\".format(image_dir)\n","    for f in files[0]:\n","        assert PathManager.isfile(f), f\n","    return files\n","\n","\n","def load_cityscapes_instances(image_dir, gt_dir, from_json=True, to_polygons=True):\n","    \"\"\"\n","    Args:\n","        image_dir (str): path to the raw dataset. e.g., \"~/cityscapes/leftImg8bit/train\".\n","        gt_dir (str): path to the raw annotations. e.g., \"~/cityscapes/gtFine/train\".\n","        from_json (bool): whether to read annotations from the raw json file or the png files.\n","        to_polygons (bool): whether to represent the segmentation as polygons\n","            (COCO's format) instead of masks (cityscapes's format).\n","\n","    Returns:\n","        list[dict]: a list of dicts in Detectron2 standard format. (See\n","        `Using Custom Datasets </tutorials/datasets.html>`_ )\n","    \"\"\"\n","    if from_json:\n","        assert to_polygons, (\n","            \"Cityscapes's json annotations are in polygon format. \"\n","            \"Converting to mask format is not supported now.\"\n","        )\n","    files = _get_cityscapes_files(image_dir, gt_dir)\n","\n","    logger.info(\"Preprocessing cityscapes annotations ...\")\n","    # This is still not fast: all workers will execute duplicate works and will\n","    # take up to 10m on a 8GPU server.\n","    pool = mp.Pool(processes=max(mp.cpu_count() // get_world_size() // 2, 4))\n","\n","    ret = pool.map(\n","        functools.partial(_cityscapes_files_to_dict, from_json=from_json, to_polygons=to_polygons),\n","        files,\n","    )\n","    logger.info(\"Loaded {} images from {}\".format(len(ret), image_dir))\n","\n","    # Map cityscape ids to contiguous ids\n","    from cityscapesscripts.helpers.labels import labels\n","\n","    labels = [l for l in labels if l.hasInstances and not l.ignoreInEval]\n","    dataset_id_to_contiguous_id = {l.id: idx for idx, l in enumerate(labels)}\n","    for dict_per_image in ret:\n","        for anno in dict_per_image[\"annotations\"]:\n","            anno[\"category_id\"] = dataset_id_to_contiguous_id[anno[\"category_id\"]]\n","    return ret\n","\n","\n","def load_cityscapes_semantic(image_dir, gt_dir):\n","    \"\"\"\n","    Args:\n","        image_dir (str): path to the raw dataset. e.g., \"~/cityscapes/leftImg8bit/train\".\n","        gt_dir (str): path to the raw annotations. e.g., \"~/cityscapes/gtFine/train\".\n","\n","    Returns:\n","        list[dict]: a list of dict, each has \"file_name\" and\n","            \"sem_seg_file_name\".\n","    \"\"\"\n","    ret = []\n","    # gt_dir is small and contain many small files. make sense to fetch to local first\n","    gt_dir = PathManager.get_local_path(gt_dir)\n","    for image_file, _, label_file, json_file in _get_cityscapes_files(image_dir, gt_dir):\n","        label_file = label_file.replace(\"labelIds\", \"labelTrainIds\")\n","\n","        with PathManager.open(json_file, \"r\") as f:\n","            jsonobj = json.load(f)\n","        ret.append(\n","            {\n","                \"file_name\": image_file,\n","                \"sem_seg_file_name\": label_file,\n","                \"height\": jsonobj[\"imgHeight\"],\n","                \"width\": jsonobj[\"imgWidth\"],\n","            }\n","        )\n","    assert len(ret), f\"No images found in {image_dir}!\"\n","    assert PathManager.isfile(\n","        ret[0][\"sem_seg_file_name\"]\n","    ), \"Please generate labelTrainIds.png with cityscapesscripts/preparation/createTrainIdLabelImgs.py\"  # noqa\n","    return ret\n","\n","\n","def _cityscapes_files_to_dict(files, from_json, to_polygons):\n","    \"\"\"\n","    Parse cityscapes annotation files to a instance segmentation dataset dict.\n","\n","    Args:\n","        files (tuple): consists of (image_file, instance_id_file, label_id_file, json_file)\n","        from_json (bool): whether to read annotations from the raw json file or the png files.\n","        to_polygons (bool): whether to represent the segmentation as polygons\n","            (COCO's format) instead of masks (cityscapes's format).\n","\n","    Returns:\n","        A dict in Detectron2 Dataset format.\n","    \"\"\"\n","    from cityscapesscripts.helpers.labels import id2label, name2label\n","\n","    image_file, instance_id_file, _, json_file = files\n","\n","    annos = []\n","\n","    if from_json:\n","        from shapely.geometry import MultiPolygon, Polygon\n","\n","        with PathManager.open(json_file, \"r\") as f:\n","            jsonobj = json.load(f)\n","        ret = {\n","            \"file_name\": image_file,\n","            \"image_id\": os.path.basename(image_file),\n","            \"height\": jsonobj[\"imgHeight\"],\n","            \"width\": jsonobj[\"imgWidth\"],\n","        }\n","\n","        # `polygons_union` contains the union of all valid polygons.\n","        polygons_union = Polygon()\n","\n","        # CityscapesScripts draw the polygons in sequential order\n","        # and each polygon *overwrites* existing ones. See\n","        # (https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/preparation/json2instanceImg.py) # noqa\n","        # We use reverse order, and each polygon *avoids* early ones.\n","        # This will resolve the ploygon overlaps in the same way as CityscapesScripts.\n","        for obj in jsonobj[\"objects\"][::-1]:\n","            if \"deleted\" in obj:  # cityscapes data format specific\n","                continue\n","            label_name = obj[\"label\"]\n","\n","            try:\n","                label = name2label[label_name]\n","            except KeyError:\n","                if label_name.endswith(\"group\"):  # crowd area\n","                    label = name2label[label_name[: -len(\"group\")]]\n","                else:\n","                    raise\n","            if label.id < 0:  # cityscapes data format\n","                continue\n","\n","            # Cityscapes's raw annotations uses integer coordinates\n","            # Therefore +0.5 here\n","            poly_coord = np.asarray(obj[\"polygon\"], dtype=\"f4\") + 0.5\n","            # CityscapesScript uses PIL.ImageDraw.polygon to rasterize\n","            # polygons for evaluation. This function operates in integer space\n","            # and draws each pixel whose center falls into the polygon.\n","            # Therefore it draws a polygon which is 0.5 \"fatter\" in expectation.\n","            # We therefore dilate the input polygon by 0.5 as our input.\n","            poly = Polygon(poly_coord).buffer(0.5, resolution=4)\n","\n","            if not label.hasInstances or label.ignoreInEval:\n","                # even if we won't store the polygon it still contributes to overlaps resolution\n","                polygons_union = polygons_union.union(poly)\n","                continue\n","\n","            # Take non-overlapping part of the polygon\n","            poly_wo_overlaps = poly.difference(polygons_union)\n","            if poly_wo_overlaps.is_empty:\n","                continue\n","            polygons_union = polygons_union.union(poly)\n","\n","            anno = {}\n","            anno[\"iscrowd\"] = label_name.endswith(\"group\")\n","            anno[\"category_id\"] = label.id\n","\n","            if isinstance(poly_wo_overlaps, Polygon):\n","                poly_list = [poly_wo_overlaps]\n","            elif isinstance(poly_wo_overlaps, MultiPolygon):\n","                poly_list = poly_wo_overlaps.geoms\n","            else:\n","                raise NotImplementedError(\"Unknown geometric structure {}\".format(poly_wo_overlaps))\n","\n","            poly_coord = []\n","            for poly_el in poly_list:\n","                # COCO API can work only with exterior boundaries now, hence we store only them.\n","                # TODO: store both exterior and interior boundaries once other parts of the\n","                # codebase support holes in polygons.\n","                poly_coord.append(list(chain(*poly_el.exterior.coords)))\n","            anno[\"segmentation\"] = poly_coord\n","            (xmin, ymin, xmax, ymax) = poly_wo_overlaps.bounds\n","\n","            anno[\"bbox\"] = (xmin, ymin, xmax, ymax)\n","            anno[\"bbox_mode\"] = BoxMode.XYXY_ABS\n","\n","            annos.append(anno)\n","    else:\n","        # See also the official annotation parsing scripts at\n","        # https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/evaluation/instances2dict.py  # noqa\n","        with PathManager.open(instance_id_file, \"rb\") as f:\n","            inst_image = np.asarray(Image.open(f), order=\"F\")\n","        # ids < 24 are stuff labels (filtering them first is about 5% faster)\n","        flattened_ids = np.unique(inst_image[inst_image >= 24])\n","\n","        ret = {\n","            \"file_name\": image_file,\n","            \"image_id\": os.path.basename(image_file),\n","            \"height\": inst_image.shape[0],\n","            \"width\": inst_image.shape[1],\n","        }\n","\n","        for instance_id in flattened_ids:\n","            # For non-crowd annotations, instance_id // 1000 is the label_id\n","            # Crowd annotations have <1000 instance ids\n","            label_id = instance_id // 1000 if instance_id >= 1000 else instance_id\n","            label = id2label[label_id]\n","            if not label.hasInstances or label.ignoreInEval:\n","                continue\n","\n","            anno = {}\n","            anno[\"iscrowd\"] = instance_id < 1000\n","            anno[\"category_id\"] = label.id\n","\n","            mask = np.asarray(inst_image == instance_id, dtype=np.uint8, order=\"F\")\n","\n","            inds = np.nonzero(mask)\n","            ymin, ymax = inds[0].min(), inds[0].max()\n","            xmin, xmax = inds[1].min(), inds[1].max()\n","            anno[\"bbox\"] = (xmin, ymin, xmax, ymax)\n","            if xmax <= xmin or ymax <= ymin:\n","                continue\n","            anno[\"bbox_mode\"] = BoxMode.XYXY_ABS\n","            if to_polygons:\n","                # This conversion comes from D4809743 and D5171122,\n","                # when Mask-RCNN was first developed.\n","                contours = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[\n","                    -2\n","                ]\n","                polygons = [c.reshape(-1).tolist() for c in contours if len(c) >= 3]\n","                # opencv's can produce invalid polygons\n","                if len(polygons) == 0:\n","                    continue\n","                anno[\"segmentation\"] = polygons\n","            else:\n","                anno[\"segmentation\"] = mask_util.encode(mask[:, :, None])[0]\n","            annos.append(anno)\n","    ret[\"annotations\"] = annos\n","    return ret"],"metadata":{"id":"f-hHKQo1JB7B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cityscapes_classes = [k.name for k in labels if k.hasInstances and not k.ignoreInEval]\n","\n","image_dir = \"/content/drive/MyDrive/datasets/cityscapes/leftImg8bit/\"\n","gt_dir = \"/content/drive/MyDrive/datasets/cityscapes/gtFine/\"\n","\n","for d in [\"train\"]:\n","  DatasetCatalog.register(\"cityscapes_\" + d, lambda x=image_dir+d, y=gt_dir+d: load_cityscapes_instances(x, y))\n","  MetadataCatalog.get(\"cityscapes_\" + d).set(thing_classes=cityscapes_classes, evaluator_type=\"coco\")\n","\n","for d in [\"val\"]:\n","  DatasetCatalog.register(\"cityscapes_\" + d, lambda x=image_dir+d, y=gt_dir+d: load_cityscapes_instances(x, y))\n","  MetadataCatalog.get(\"cityscapes_\" + d).set(thing_classes=cityscapes_classes, evaluator_type=\"coco\")\n","\n","for d in [\"test\"]:\n","  DatasetCatalog.register(\"cityscapes_\" + d, lambda x=image_dir+d, y=gt_dir+d: load_cityscapes_instances(x, y))\n","  MetadataCatalog.get(\"cityscapes_\" + d).set(thing_classes=cityscapes_classes, evaluator_type=\"coco\")"],"metadata":{"id":"J9FG2TWCJISH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from detectron2.engine import DefaultTrainer\n","\n","\n","cfg = get_cfg()\n","cfg.merge_from_file(model_BM_ResNet_101)\n","cfg.DATASETS.TRAIN = (\"cityscapes_train\",)\n","cfg.DATASETS.TEST = ()\n","cfg.MODEL.WEIGHTS = weight_BM_ResNet_101 \n","\n","\n","cfg.MODEL.BASIS_MODULE.NORM = \"BN\" # Not SyncBN because we have only 1 GPU and 1 machine, otherwise there is a problem with init groups of process\n","cfg.MODEL.BASIS_MODULE.NUM_CLASSES = 8 # Classi di Cityscapes\n","cfg.MODEL.FCOS.NUM_CLASSES = 8\n","cfg.MODEL.MEInst.NUM_CLASSES = 8\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 8\n","\n","cfg.MODEL.BASIS_MODULE.LOSS_ON = False\n","\n","\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n","cfg.SOLVER.IMS_PER_BATCH = 1\n","cfg.SOLVER.BASE_LR = 0.001\n","cfg.SOLVER.MAX_ITER = 2000\n","cfg.SOLVER.STEPS = (1500,)\n","\n","\n","\n","\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","trainer = DefaultTrainer(cfg)\n","trainer.resume_or_load(resume=False)\n","trainer.train()"],"metadata":{"id":"CTBxmgluJLFc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644159754200,"user_tz":-60,"elapsed":2966353,"user":{"displayName":"muchsb 2021","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioRvCcJyMu2pLImQLAH9SrtPIxQR-65c4Rc0Lq=s64","userId":"04872446583146860130"}},"outputId":"f911f6e1-23ad-44cf-ca05-e5e54a41f720"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/06 14:13:07 d2.config.compat]: \u001b[0mConfig 'configs/BlendMask/R_101_3x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n","\u001b[32m[02/06 14:13:21 d2.engine.defaults]: \u001b[0mModel:\n","BlendMask(\n","  (backbone): FPN(\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelP6P7(\n","      (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    )\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (6): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (7): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (8): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (9): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (10): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (11): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (12): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (13): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (14): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (15): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (16): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (17): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (18): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (19): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (20): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (21): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (22): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): FCOS(\n","    (fcos_head): FCOSHead(\n","      (cls_tower): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n","        (2): ReLU()\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (4): GroupNorm(32, 256, eps=1e-05, affine=True)\n","        (5): ReLU()\n","        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (7): GroupNorm(32, 256, eps=1e-05, affine=True)\n","        (8): ReLU()\n","        (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (10): GroupNorm(32, 256, eps=1e-05, affine=True)\n","        (11): ReLU()\n","      )\n","      (bbox_tower): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n","        (2): ReLU()\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (4): GroupNorm(32, 256, eps=1e-05, affine=True)\n","        (5): ReLU()\n","        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (7): GroupNorm(32, 256, eps=1e-05, affine=True)\n","        (8): ReLU()\n","        (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (10): GroupNorm(32, 256, eps=1e-05, affine=True)\n","        (11): ReLU()\n","      )\n","      (share_tower): Sequential()\n","      (cls_logits): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bbox_pred): Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (ctrness): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (fcos_outputs): FCOSOutputs(\n","      (loc_loss_func): IOULoss()\n","    )\n","  )\n","  (basis_module): ProtoNet(\n","    (refine): ModuleList(\n","      (0): Sequential(\n","        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (1): Sequential(\n","        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (2): Sequential(\n","        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","    )\n","    (tower): Sequential(\n","      (0): Sequential(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (1): Sequential(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (2): Sequential(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (3): Upsample(scale_factor=2.0, mode=bilinear)\n","      (4): Sequential(\n","        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (5): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (top_layer): Conv2d(256, 784, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",")\n","\u001b[32m[02/06 14:19:22 d2.data.build]: \u001b[0mRemoved 10 images with no usable annotations. 2965 images left.\n","\u001b[32m[02/06 14:19:22 d2.data.build]: \u001b[0mDistribution of instances among all 8 categories:\n","\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n","|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n","|   person   | 17918        |   rider    | 1781         |    car     | 26963        |\n","|   truck    | 484          |    bus     | 380          |   train    | 168          |\n","| motorcycle | 737          |  bicycle   | 3675         |            |              |\n","|   total    | 52106        |            |              |            |              |\u001b[0m\n","\u001b[32m[02/06 14:19:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[02/06 14:19:22 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[02/06 14:19:22 d2.data.common]: \u001b[0mSerializing 2965 elements to byte tensors and concatenating them all ...\n","\u001b[32m[02/06 14:19:22 d2.data.common]: \u001b[0mSerialized dataset takes 67.23 MiB\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Skip loading parameter 'proposal_generator.fcos_head.cls_logits.weight' to the model due to incompatible shapes: (80, 256, 3, 3) in the checkpoint but (8, 256, 3, 3) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'proposal_generator.fcos_head.cls_logits.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n","Some model parameters or buffers are not found in the checkpoint:\n","\u001b[34mproposal_generator.fcos_head.cls_logits.{bias, weight}\u001b[0m\n","The checkpoint state_dict contains keys that are not used by the model:\n","  \u001b[35mbasis_module.seg_head.0.weight\u001b[0m\n","  \u001b[35mbasis_module.seg_head.1.{bias, num_batches_tracked, running_mean, running_var, weight}\u001b[0m\n","  \u001b[35mbasis_module.seg_head.3.weight\u001b[0m\n","  \u001b[35mbasis_module.seg_head.4.{bias, num_batches_tracked, running_mean, running_var, weight}\u001b[0m\n","  \u001b[35mbasis_module.seg_head.6.{bias, weight}\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32m[02/06 14:19:28 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  max_size = (max_size + (stride - 1)) // stride * stride\n","/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32m[02/06 14:19:56 d2.utils.events]: \u001b[0m eta: 0:42:46  iter: 19  total_loss: 2.213  loss_mask: 0.288  loss_fcos_cls: 1.102  loss_fcos_loc: 0.204  loss_fcos_ctr: 0.6277  time: 1.3437  data_time: 0.0495  lr: 1.9981e-05  max_mem: 2092M\n","\u001b[32m[02/06 14:20:21 d2.utils.events]: \u001b[0m eta: 0:42:23  iter: 39  total_loss: 2.188  loss_mask: 0.2884  loss_fcos_cls: 1.056  loss_fcos_loc: 0.1967  loss_fcos_ctr: 0.6171  time: 1.3100  data_time: 0.0045  lr: 3.9961e-05  max_mem: 2092M\n","\u001b[32m[02/06 14:20:47 d2.utils.events]: \u001b[0m eta: 0:42:01  iter: 59  total_loss: 2.098  loss_mask: 0.2643  loss_fcos_cls: 1.023  loss_fcos_loc: 0.214  loss_fcos_ctr: 0.6277  time: 1.3013  data_time: 0.0052  lr: 5.9941e-05  max_mem: 2092M\n","\u001b[32m[02/06 14:21:13 d2.utils.events]: \u001b[0m eta: 0:41:36  iter: 79  total_loss: 1.86  loss_mask: 0.2226  loss_fcos_cls: 0.8302  loss_fcos_loc: 0.1838  loss_fcos_ctr: 0.619  time: 1.2979  data_time: 0.0048  lr: 7.9921e-05  max_mem: 2092M\n","\u001b[32m[02/06 14:21:39 d2.utils.events]: \u001b[0m eta: 0:41:12  iter: 99  total_loss: 1.743  loss_mask: 0.2933  loss_fcos_cls: 0.5873  loss_fcos_loc: 0.2114  loss_fcos_ctr: 0.6269  time: 1.2975  data_time: 0.0045  lr: 9.9901e-05  max_mem: 2092M\n","\u001b[32m[02/06 14:22:04 d2.utils.events]: \u001b[0m eta: 0:40:50  iter: 119  total_loss: 1.446  loss_mask: 0.2569  loss_fcos_cls: 0.3716  loss_fcos_loc: 0.2126  loss_fcos_ctr: 0.6213  time: 1.2939  data_time: 0.0059  lr: 0.00011988  max_mem: 2092M\n","\u001b[32m[02/06 14:22:30 d2.utils.events]: \u001b[0m eta: 0:40:25  iter: 139  total_loss: 1.452  loss_mask: 0.2795  loss_fcos_cls: 0.4153  loss_fcos_loc: 0.1869  loss_fcos_ctr: 0.6183  time: 1.2924  data_time: 0.0056  lr: 0.00013986  max_mem: 2092M\n","\u001b[32m[02/06 14:22:56 d2.utils.events]: \u001b[0m eta: 0:39:59  iter: 159  total_loss: 1.53  loss_mask: 0.2955  loss_fcos_cls: 0.4113  loss_fcos_loc: 0.204  loss_fcos_ctr: 0.6205  time: 1.2922  data_time: 0.0050  lr: 0.00015984  max_mem: 2092M\n","\u001b[32m[02/06 14:23:22 d2.utils.events]: \u001b[0m eta: 0:39:33  iter: 179  total_loss: 1.592  loss_mask: 0.2641  loss_fcos_cls: 0.3699  loss_fcos_loc: 0.2149  loss_fcos_ctr: 0.6303  time: 1.2908  data_time: 0.0057  lr: 0.00017982  max_mem: 2092M\n","\u001b[32m[02/06 14:23:47 d2.utils.events]: \u001b[0m eta: 0:39:07  iter: 199  total_loss: 1.537  loss_mask: 0.315  loss_fcos_cls: 0.3645  loss_fcos_loc: 0.2099  loss_fcos_ctr: 0.6201  time: 1.2890  data_time: 0.0050  lr: 0.0001998  max_mem: 2092M\n","\u001b[32m[02/06 14:24:13 d2.utils.events]: \u001b[0m eta: 0:38:42  iter: 219  total_loss: 1.312  loss_mask: 0.2605  loss_fcos_cls: 0.2543  loss_fcos_loc: 0.1947  loss_fcos_ctr: 0.6252  time: 1.2902  data_time: 0.0041  lr: 0.00021978  max_mem: 2092M\n","\u001b[32m[02/06 14:24:39 d2.utils.events]: \u001b[0m eta: 0:38:16  iter: 239  total_loss: 1.322  loss_mask: 0.2611  loss_fcos_cls: 0.2194  loss_fcos_loc: 0.166  loss_fcos_ctr: 0.6116  time: 1.2907  data_time: 0.0047  lr: 0.00023976  max_mem: 2092M\n","\u001b[32m[02/06 14:25:05 d2.utils.events]: \u001b[0m eta: 0:37:50  iter: 259  total_loss: 1.349  loss_mask: 0.2513  loss_fcos_cls: 0.2731  loss_fcos_loc: 0.184  loss_fcos_ctr: 0.6215  time: 1.2908  data_time: 0.0048  lr: 0.00025974  max_mem: 2092M\n","\u001b[32m[02/06 14:25:31 d2.utils.events]: \u001b[0m eta: 0:37:25  iter: 279  total_loss: 1.406  loss_mask: 0.2947  loss_fcos_cls: 0.2634  loss_fcos_loc: 0.2204  loss_fcos_ctr: 0.624  time: 1.2913  data_time: 0.0060  lr: 0.00027972  max_mem: 2092M\n","\u001b[32m[02/06 14:25:57 d2.utils.events]: \u001b[0m eta: 0:36:59  iter: 299  total_loss: 1.384  loss_mask: 0.2912  loss_fcos_cls: 0.2342  loss_fcos_loc: 0.2164  loss_fcos_ctr: 0.6282  time: 1.2911  data_time: 0.0059  lr: 0.0002997  max_mem: 2092M\n","\u001b[32m[02/06 14:26:22 d2.utils.events]: \u001b[0m eta: 0:36:33  iter: 319  total_loss: 1.352  loss_mask: 0.2627  loss_fcos_cls: 0.2555  loss_fcos_loc: 0.1841  loss_fcos_ctr: 0.6143  time: 1.2908  data_time: 0.0039  lr: 0.00031968  max_mem: 2092M\n","\u001b[32m[02/06 14:26:49 d2.utils.events]: \u001b[0m eta: 0:36:07  iter: 339  total_loss: 1.349  loss_mask: 0.2614  loss_fcos_cls: 0.2199  loss_fcos_loc: 0.2185  loss_fcos_ctr: 0.6313  time: 1.2917  data_time: 0.0052  lr: 0.00033966  max_mem: 2092M\n","\u001b[32m[02/06 14:27:14 d2.utils.events]: \u001b[0m eta: 0:35:41  iter: 359  total_loss: 1.273  loss_mask: 0.2252  loss_fcos_cls: 0.2351  loss_fcos_loc: 0.1527  loss_fcos_ctr: 0.6198  time: 1.2918  data_time: 0.0044  lr: 0.00035964  max_mem: 2092M\n","\u001b[32m[02/06 14:27:40 d2.utils.events]: \u001b[0m eta: 0:35:15  iter: 379  total_loss: 1.489  loss_mask: 0.3321  loss_fcos_cls: 0.2555  loss_fcos_loc: 0.2746  loss_fcos_ctr: 0.6401  time: 1.2911  data_time: 0.0055  lr: 0.00037962  max_mem: 2092M\n","\u001b[32m[02/06 14:28:06 d2.utils.events]: \u001b[0m eta: 0:34:50  iter: 399  total_loss: 1.381  loss_mask: 0.3036  loss_fcos_cls: 0.2267  loss_fcos_loc: 0.1825  loss_fcos_ctr: 0.6241  time: 1.2915  data_time: 0.0062  lr: 0.0003996  max_mem: 2092M\n","\u001b[32m[02/06 14:28:32 d2.utils.events]: \u001b[0m eta: 0:34:23  iter: 419  total_loss: 1.299  loss_mask: 0.2668  loss_fcos_cls: 0.2216  loss_fcos_loc: 0.1925  loss_fcos_ctr: 0.626  time: 1.2912  data_time: 0.0049  lr: 0.00041958  max_mem: 2092M\n","\u001b[32m[02/06 14:28:57 d2.utils.events]: \u001b[0m eta: 0:33:57  iter: 439  total_loss: 2.103  loss_mask: 0.2935  loss_fcos_cls: 0.9815  loss_fcos_loc: 0.2386  loss_fcos_ctr: 0.6269  time: 1.2904  data_time: 0.0048  lr: 0.00043956  max_mem: 2092M\n","\u001b[32m[02/06 14:29:23 d2.utils.events]: \u001b[0m eta: 0:33:31  iter: 459  total_loss: 2.33  loss_mask: 0.3045  loss_fcos_cls: 1.209  loss_fcos_loc: 0.236  loss_fcos_ctr: 0.6325  time: 1.2910  data_time: 0.0052  lr: 0.00045954  max_mem: 2092M\n","\u001b[32m[02/06 14:29:49 d2.utils.events]: \u001b[0m eta: 0:33:05  iter: 479  total_loss: 2.049  loss_mask: 0.2778  loss_fcos_cls: 0.8469  loss_fcos_loc: 0.2078  loss_fcos_ctr: 0.6296  time: 1.2910  data_time: 0.0045  lr: 0.00047952  max_mem: 2092M\n","\u001b[32m[02/06 14:30:15 d2.utils.events]: \u001b[0m eta: 0:32:39  iter: 499  total_loss: 1.69  loss_mask: 0.2586  loss_fcos_cls: 0.5783  loss_fcos_loc: 0.2027  loss_fcos_ctr: 0.6273  time: 1.2905  data_time: 0.0053  lr: 0.0004995  max_mem: 2092M\n","\u001b[32m[02/06 14:30:41 d2.utils.events]: \u001b[0m eta: 0:32:13  iter: 519  total_loss: 1.479  loss_mask: 0.284  loss_fcos_cls: 0.3083  loss_fcos_loc: 0.2041  loss_fcos_ctr: 0.6259  time: 1.2908  data_time: 0.0055  lr: 0.00051948  max_mem: 2092M\n","\u001b[32m[02/06 14:31:07 d2.utils.events]: \u001b[0m eta: 0:31:47  iter: 539  total_loss: 1.243  loss_mask: 0.237  loss_fcos_cls: 0.2659  loss_fcos_loc: 0.1734  loss_fcos_ctr: 0.618  time: 1.2905  data_time: 0.0055  lr: 0.00053946  max_mem: 2092M\n","\u001b[32m[02/06 14:31:32 d2.utils.events]: \u001b[0m eta: 0:31:21  iter: 559  total_loss: 1.404  loss_mask: 0.29  loss_fcos_cls: 0.2439  loss_fcos_loc: 0.2134  loss_fcos_ctr: 0.6279  time: 1.2905  data_time: 0.0054  lr: 0.00055944  max_mem: 2092M\n","\u001b[32m[02/06 14:31:58 d2.utils.events]: \u001b[0m eta: 0:30:54  iter: 579  total_loss: 1.313  loss_mask: 0.2386  loss_fcos_cls: 0.2422  loss_fcos_loc: 0.1873  loss_fcos_ctr: 0.622  time: 1.2908  data_time: 0.0044  lr: 0.00057942  max_mem: 2092M\n","\u001b[32m[02/06 14:32:24 d2.utils.events]: \u001b[0m eta: 0:30:29  iter: 599  total_loss: 1.39  loss_mask: 0.2891  loss_fcos_cls: 0.2342  loss_fcos_loc: 0.2242  loss_fcos_ctr: 0.6178  time: 1.2908  data_time: 0.0054  lr: 0.0005994  max_mem: 2092M\n","\u001b[32m[02/06 14:32:50 d2.utils.events]: \u001b[0m eta: 0:30:02  iter: 619  total_loss: 1.204  loss_mask: 0.2292  loss_fcos_cls: 0.204  loss_fcos_loc: 0.1889  loss_fcos_ctr: 0.6204  time: 1.2909  data_time: 0.0053  lr: 0.00061938  max_mem: 2096M\n","\u001b[32m[02/06 14:33:16 d2.utils.events]: \u001b[0m eta: 0:29:36  iter: 639  total_loss: 1.29  loss_mask: 0.282  loss_fcos_cls: 0.221  loss_fcos_loc: 0.177  loss_fcos_ctr: 0.6172  time: 1.2907  data_time: 0.0059  lr: 0.00063936  max_mem: 2096M\n","\u001b[32m[02/06 14:33:42 d2.utils.events]: \u001b[0m eta: 0:29:10  iter: 659  total_loss: 1.396  loss_mask: 0.282  loss_fcos_cls: 0.2508  loss_fcos_loc: 0.2079  loss_fcos_ctr: 0.6264  time: 1.2903  data_time: 0.0039  lr: 0.00065934  max_mem: 2096M\n","\u001b[32m[02/06 14:34:08 d2.utils.events]: \u001b[0m eta: 0:28:44  iter: 679  total_loss: 1.278  loss_mask: 0.2515  loss_fcos_cls: 0.1905  loss_fcos_loc: 0.1844  loss_fcos_ctr: 0.617  time: 1.2905  data_time: 0.0050  lr: 0.00067932  max_mem: 2096M\n","\u001b[32m[02/06 14:34:33 d2.utils.events]: \u001b[0m eta: 0:28:18  iter: 699  total_loss: 1.36  loss_mask: 0.2759  loss_fcos_cls: 0.1941  loss_fcos_loc: 0.2273  loss_fcos_ctr: 0.6235  time: 1.2907  data_time: 0.0059  lr: 0.0006993  max_mem: 2096M\n","\u001b[32m[02/06 14:34:59 d2.utils.events]: \u001b[0m eta: 0:27:52  iter: 719  total_loss: 1.408  loss_mask: 0.3154  loss_fcos_cls: 0.2192  loss_fcos_loc: 0.2139  loss_fcos_ctr: 0.6252  time: 1.2907  data_time: 0.0050  lr: 0.00071928  max_mem: 2096M\n","\u001b[32m[02/06 14:35:25 d2.utils.events]: \u001b[0m eta: 0:27:26  iter: 739  total_loss: 1.334  loss_mask: 0.2843  loss_fcos_cls: 0.2337  loss_fcos_loc: 0.1929  loss_fcos_ctr: 0.6278  time: 1.2905  data_time: 0.0059  lr: 0.00073926  max_mem: 2096M\n","\u001b[32m[02/06 14:35:51 d2.utils.events]: \u001b[0m eta: 0:27:00  iter: 759  total_loss: 1.306  loss_mask: 0.2837  loss_fcos_cls: 0.2005  loss_fcos_loc: 0.2028  loss_fcos_ctr: 0.6279  time: 1.2906  data_time: 0.0048  lr: 0.00075924  max_mem: 2096M\n","\u001b[32m[02/06 14:36:17 d2.utils.events]: \u001b[0m eta: 0:26:34  iter: 779  total_loss: 1.339  loss_mask: 0.309  loss_fcos_cls: 0.1893  loss_fcos_loc: 0.2083  loss_fcos_ctr: 0.621  time: 1.2905  data_time: 0.0052  lr: 0.00077922  max_mem: 2096M\n","\u001b[32m[02/06 14:36:42 d2.utils.events]: \u001b[0m eta: 0:26:07  iter: 799  total_loss: 1.233  loss_mask: 0.2618  loss_fcos_cls: 0.1835  loss_fcos_loc: 0.1795  loss_fcos_ctr: 0.6164  time: 1.2902  data_time: 0.0046  lr: 0.0007992  max_mem: 2096M\n","\u001b[32m[02/06 14:37:08 d2.utils.events]: \u001b[0m eta: 0:25:41  iter: 819  total_loss: 1.228  loss_mask: 0.2565  loss_fcos_cls: 0.2106  loss_fcos_loc: 0.187  loss_fcos_ctr: 0.616  time: 1.2900  data_time: 0.0050  lr: 0.00081918  max_mem: 2096M\n","\u001b[32m[02/06 14:37:34 d2.utils.events]: \u001b[0m eta: 0:25:15  iter: 839  total_loss: 1.282  loss_mask: 0.2947  loss_fcos_cls: 0.1989  loss_fcos_loc: 0.1908  loss_fcos_ctr: 0.6279  time: 1.2900  data_time: 0.0056  lr: 0.00083916  max_mem: 2096M\n","\u001b[32m[02/06 14:37:59 d2.utils.events]: \u001b[0m eta: 0:24:49  iter: 859  total_loss: 1.303  loss_mask: 0.2481  loss_fcos_cls: 0.2134  loss_fcos_loc: 0.19  loss_fcos_ctr: 0.6157  time: 1.2897  data_time: 0.0054  lr: 0.00085914  max_mem: 2096M\n","\u001b[32m[02/06 14:38:25 d2.utils.events]: \u001b[0m eta: 0:24:23  iter: 879  total_loss: 1.279  loss_mask: 0.2223  loss_fcos_cls: 0.203  loss_fcos_loc: 0.1872  loss_fcos_ctr: 0.6109  time: 1.2899  data_time: 0.0050  lr: 0.00087912  max_mem: 2096M\n","\u001b[32m[02/06 14:38:51 d2.utils.events]: \u001b[0m eta: 0:23:57  iter: 899  total_loss: 1.306  loss_mask: 0.2678  loss_fcos_cls: 0.2061  loss_fcos_loc: 0.2025  loss_fcos_ctr: 0.6206  time: 1.2900  data_time: 0.0054  lr: 0.0008991  max_mem: 2096M\n","\u001b[32m[02/06 14:39:17 d2.utils.events]: \u001b[0m eta: 0:23:31  iter: 919  total_loss: 1.142  loss_mask: 0.2047  loss_fcos_cls: 0.1459  loss_fcos_loc: 0.1609  loss_fcos_ctr: 0.6113  time: 1.2903  data_time: 0.0046  lr: 0.00091908  max_mem: 2096M\n","\u001b[32m[02/06 14:39:43 d2.utils.events]: \u001b[0m eta: 0:23:05  iter: 939  total_loss: 1.334  loss_mask: 0.2808  loss_fcos_cls: 0.1942  loss_fcos_loc: 0.2248  loss_fcos_ctr: 0.6251  time: 1.2902  data_time: 0.0049  lr: 0.00093906  max_mem: 2096M\n","\u001b[32m[02/06 14:40:09 d2.utils.events]: \u001b[0m eta: 0:22:38  iter: 959  total_loss: 1.307  loss_mask: 0.2531  loss_fcos_cls: 0.2286  loss_fcos_loc: 0.1904  loss_fcos_ctr: 0.6144  time: 1.2902  data_time: 0.0046  lr: 0.00095904  max_mem: 2096M\n","\u001b[32m[02/06 14:40:35 d2.utils.events]: \u001b[0m eta: 0:22:12  iter: 979  total_loss: 1.348  loss_mask: 0.2578  loss_fcos_cls: 0.1941  loss_fcos_loc: 0.23  loss_fcos_ctr: 0.6323  time: 1.2904  data_time: 0.0054  lr: 0.00097902  max_mem: 2128M\n","\u001b[32m[02/06 14:41:01 d2.utils.events]: \u001b[0m eta: 0:21:46  iter: 999  total_loss: 1.263  loss_mask: 0.2715  loss_fcos_cls: 0.191  loss_fcos_loc: 0.1935  loss_fcos_ctr: 0.6173  time: 1.2904  data_time: 0.0051  lr: 0.000999  max_mem: 2128M\n","\u001b[32m[02/06 14:41:26 d2.utils.events]: \u001b[0m eta: 0:21:20  iter: 1019  total_loss: 1.283  loss_mask: 0.2624  loss_fcos_cls: 0.1821  loss_fcos_loc: 0.2013  loss_fcos_ctr: 0.6235  time: 1.2898  data_time: 0.0052  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:41:52 d2.utils.events]: \u001b[0m eta: 0:20:54  iter: 1039  total_loss: 1.296  loss_mask: 0.2846  loss_fcos_cls: 0.1818  loss_fcos_loc: 0.2152  loss_fcos_ctr: 0.618  time: 1.2898  data_time: 0.0047  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:42:17 d2.utils.events]: \u001b[0m eta: 0:20:28  iter: 1059  total_loss: 1.293  loss_mask: 0.2624  loss_fcos_cls: 0.1966  loss_fcos_loc: 0.198  loss_fcos_ctr: 0.6296  time: 1.2895  data_time: 0.0053  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:42:43 d2.utils.events]: \u001b[0m eta: 0:20:02  iter: 1079  total_loss: 1.461  loss_mask: 0.3011  loss_fcos_cls: 0.2575  loss_fcos_loc: 0.2392  loss_fcos_ctr: 0.6348  time: 1.2896  data_time: 0.0052  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:43:09 d2.utils.events]: \u001b[0m eta: 0:19:36  iter: 1099  total_loss: 1.243  loss_mask: 0.2768  loss_fcos_cls: 0.2029  loss_fcos_loc: 0.199  loss_fcos_ctr: 0.62  time: 1.2894  data_time: 0.0054  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:43:35 d2.utils.events]: \u001b[0m eta: 0:19:10  iter: 1119  total_loss: 1.353  loss_mask: 0.271  loss_fcos_cls: 0.2161  loss_fcos_loc: 0.2294  loss_fcos_ctr: 0.6265  time: 1.2894  data_time: 0.0055  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:44:01 d2.utils.events]: \u001b[0m eta: 0:18:44  iter: 1139  total_loss: 1.292  loss_mask: 0.2766  loss_fcos_cls: 0.1969  loss_fcos_loc: 0.2123  loss_fcos_ctr: 0.625  time: 1.2895  data_time: 0.0049  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:44:27 d2.utils.events]: \u001b[0m eta: 0:18:17  iter: 1159  total_loss: 1.265  loss_mask: 0.2486  loss_fcos_cls: 0.1932  loss_fcos_loc: 0.194  loss_fcos_ctr: 0.6177  time: 1.2895  data_time: 0.0066  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:44:53 d2.utils.events]: \u001b[0m eta: 0:17:51  iter: 1179  total_loss: 1.415  loss_mask: 0.3146  loss_fcos_cls: 0.2375  loss_fcos_loc: 0.2149  loss_fcos_ctr: 0.6294  time: 1.2894  data_time: 0.0054  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:45:18 d2.utils.events]: \u001b[0m eta: 0:17:25  iter: 1199  total_loss: 1.401  loss_mask: 0.2983  loss_fcos_cls: 0.2078  loss_fcos_loc: 0.1998  loss_fcos_ctr: 0.6248  time: 1.2892  data_time: 0.0050  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:45:44 d2.utils.events]: \u001b[0m eta: 0:16:59  iter: 1219  total_loss: 1.154  loss_mask: 0.2309  loss_fcos_cls: 0.1486  loss_fcos_loc: 0.1627  loss_fcos_ctr: 0.6126  time: 1.2892  data_time: 0.0048  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:46:10 d2.utils.events]: \u001b[0m eta: 0:16:33  iter: 1239  total_loss: 1.303  loss_mask: 0.273  loss_fcos_cls: 0.1823  loss_fcos_loc: 0.1912  loss_fcos_ctr: 0.6176  time: 1.2896  data_time: 0.0054  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:46:36 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 1259  total_loss: 1.252  loss_mask: 0.2573  loss_fcos_cls: 0.1738  loss_fcos_loc: 0.1899  loss_fcos_ctr: 0.6242  time: 1.2897  data_time: 0.0045  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:47:02 d2.utils.events]: \u001b[0m eta: 0:15:41  iter: 1279  total_loss: 1.3  loss_mask: 0.2774  loss_fcos_cls: 0.1834  loss_fcos_loc: 0.1826  loss_fcos_ctr: 0.6223  time: 1.2898  data_time: 0.0042  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:47:28 d2.utils.events]: \u001b[0m eta: 0:15:14  iter: 1299  total_loss: 1.256  loss_mask: 0.251  loss_fcos_cls: 0.1994  loss_fcos_loc: 0.2058  loss_fcos_ctr: 0.6179  time: 1.2899  data_time: 0.0045  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:47:54 d2.utils.events]: \u001b[0m eta: 0:14:48  iter: 1319  total_loss: 1.139  loss_mask: 0.228  loss_fcos_cls: 0.1505  loss_fcos_loc: 0.1727  loss_fcos_ctr: 0.6141  time: 1.2899  data_time: 0.0048  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:48:20 d2.utils.events]: \u001b[0m eta: 0:14:22  iter: 1339  total_loss: 1.237  loss_mask: 0.2711  loss_fcos_cls: 0.1584  loss_fcos_loc: 0.1982  loss_fcos_ctr: 0.6263  time: 1.2899  data_time: 0.0055  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:48:46 d2.utils.events]: \u001b[0m eta: 0:13:56  iter: 1359  total_loss: 1.276  loss_mask: 0.2741  loss_fcos_cls: 0.1822  loss_fcos_loc: 0.1991  loss_fcos_ctr: 0.6273  time: 1.2899  data_time: 0.0060  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:49:12 d2.utils.events]: \u001b[0m eta: 0:13:30  iter: 1379  total_loss: 1.251  loss_mask: 0.2765  loss_fcos_cls: 0.1679  loss_fcos_loc: 0.2196  loss_fcos_ctr: 0.6296  time: 1.2900  data_time: 0.0043  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:49:37 d2.utils.events]: \u001b[0m eta: 0:13:04  iter: 1399  total_loss: 1.338  loss_mask: 0.2843  loss_fcos_cls: 0.1812  loss_fcos_loc: 0.2465  loss_fcos_ctr: 0.6234  time: 1.2898  data_time: 0.0053  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:50:03 d2.utils.events]: \u001b[0m eta: 0:12:38  iter: 1419  total_loss: 1.232  loss_mask: 0.266  loss_fcos_cls: 0.1867  loss_fcos_loc: 0.2177  loss_fcos_ctr: 0.6211  time: 1.2897  data_time: 0.0044  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:50:29 d2.utils.events]: \u001b[0m eta: 0:12:11  iter: 1439  total_loss: 1.291  loss_mask: 0.2755  loss_fcos_cls: 0.1637  loss_fcos_loc: 0.2012  loss_fcos_ctr: 0.6318  time: 1.2897  data_time: 0.0057  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:50:54 d2.utils.events]: \u001b[0m eta: 0:11:45  iter: 1459  total_loss: 1.26  loss_mask: 0.2836  loss_fcos_cls: 0.1937  loss_fcos_loc: 0.2023  loss_fcos_ctr: 0.6238  time: 1.2896  data_time: 0.0044  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:51:20 d2.utils.events]: \u001b[0m eta: 0:11:19  iter: 1479  total_loss: 1.252  loss_mask: 0.2545  loss_fcos_cls: 0.1766  loss_fcos_loc: 0.1874  loss_fcos_ctr: 0.6195  time: 1.2897  data_time: 0.0053  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:51:46 d2.utils.events]: \u001b[0m eta: 0:10:53  iter: 1499  total_loss: 1.287  loss_mask: 0.2591  loss_fcos_cls: 0.1664  loss_fcos_loc: 0.2257  loss_fcos_ctr: 0.6241  time: 1.2899  data_time: 0.0050  lr: 0.001  max_mem: 2128M\n","\u001b[32m[02/06 14:52:12 d2.utils.events]: \u001b[0m eta: 0:10:27  iter: 1519  total_loss: 1.182  loss_mask: 0.2328  loss_fcos_cls: 0.149  loss_fcos_loc: 0.1605  loss_fcos_ctr: 0.6223  time: 1.2899  data_time: 0.0053  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 14:52:38 d2.utils.events]: \u001b[0m eta: 0:10:01  iter: 1539  total_loss: 1.192  loss_mask: 0.2399  loss_fcos_cls: 0.1575  loss_fcos_loc: 0.173  loss_fcos_ctr: 0.6202  time: 1.2900  data_time: 0.0052  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 14:53:04 d2.utils.events]: \u001b[0m eta: 0:09:34  iter: 1559  total_loss: 1.296  loss_mask: 0.267  loss_fcos_cls: 0.1781  loss_fcos_loc: 0.2058  loss_fcos_ctr: 0.6298  time: 1.2902  data_time: 0.0046  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 14:53:30 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 1579  total_loss: 1.382  loss_mask: 0.3129  loss_fcos_cls: 0.1861  loss_fcos_loc: 0.2013  loss_fcos_ctr: 0.6246  time: 1.2901  data_time: 0.0060  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 14:53:56 d2.utils.events]: \u001b[0m eta: 0:08:42  iter: 1599  total_loss: 1.308  loss_mask: 0.2737  loss_fcos_cls: 0.1592  loss_fcos_loc: 0.2006  loss_fcos_ctr: 0.6176  time: 1.2902  data_time: 0.0065  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 14:54:22 d2.utils.events]: \u001b[0m eta: 0:08:16  iter: 1619  total_loss: 1.305  loss_mask: 0.2706  loss_fcos_cls: 0.1935  loss_fcos_loc: 0.2139  loss_fcos_ctr: 0.6259  time: 1.2901  data_time: 0.0049  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 14:54:48 d2.utils.events]: \u001b[0m eta: 0:07:50  iter: 1639  total_loss: 1.097  loss_mask: 0.2273  loss_fcos_cls: 0.1437  loss_fcos_loc: 0.1593  loss_fcos_ctr: 0.6058  time: 1.2901  data_time: 0.0049  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 14:55:13 d2.utils.events]: \u001b[0m eta: 0:07:24  iter: 1659  total_loss: 1.237  loss_mask: 0.2817  loss_fcos_cls: 0.153  loss_fcos_loc: 0.1752  loss_fcos_ctr: 0.6306  time: 1.2901  data_time: 0.0055  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 14:55:39 d2.utils.events]: \u001b[0m eta: 0:06:58  iter: 1679  total_loss: 1.27  loss_mask: 0.2636  loss_fcos_cls: 0.1654  loss_fcos_loc: 0.2074  loss_fcos_ctr: 0.6262  time: 1.2902  data_time: 0.0051  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 14:56:05 d2.utils.events]: \u001b[0m eta: 0:06:31  iter: 1699  total_loss: 1.267  loss_mask: 0.2921  loss_fcos_cls: 0.1705  loss_fcos_loc: 0.1897  loss_fcos_ctr: 0.6301  time: 1.2900  data_time: 0.0062  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 14:56:31 d2.utils.events]: \u001b[0m eta: 0:06:05  iter: 1719  total_loss: 1.205  loss_mask: 0.2456  loss_fcos_cls: 0.179  loss_fcos_loc: 0.1718  loss_fcos_ctr: 0.6149  time: 1.2899  data_time: 0.0044  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 14:56:57 d2.utils.events]: \u001b[0m eta: 0:05:39  iter: 1739  total_loss: 1.324  loss_mask: 0.3021  loss_fcos_cls: 0.1752  loss_fcos_loc: 0.2254  loss_fcos_ctr: 0.6226  time: 1.2901  data_time: 0.0048  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 14:57:23 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 1759  total_loss: 1.231  loss_mask: 0.2464  loss_fcos_cls: 0.1648  loss_fcos_loc: 0.1954  loss_fcos_ctr: 0.6244  time: 1.2902  data_time: 0.0055  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 14:57:48 d2.utils.events]: \u001b[0m eta: 0:04:47  iter: 1779  total_loss: 1.253  loss_mask: 0.2765  loss_fcos_cls: 0.1625  loss_fcos_loc: 0.211  loss_fcos_ctr: 0.6213  time: 1.2898  data_time: 0.0053  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 14:58:14 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 1799  total_loss: 1.291  loss_mask: 0.2684  loss_fcos_cls: 0.1691  loss_fcos_loc: 0.1881  loss_fcos_ctr: 0.6206  time: 1.2898  data_time: 0.0048  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 14:58:40 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 1819  total_loss: 1.204  loss_mask: 0.2218  loss_fcos_cls: 0.1686  loss_fcos_loc: 0.193  loss_fcos_ctr: 0.6215  time: 1.2899  data_time: 0.0052  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 14:59:06 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 1839  total_loss: 1.319  loss_mask: 0.3119  loss_fcos_cls: 0.1683  loss_fcos_loc: 0.1926  loss_fcos_ctr: 0.6243  time: 1.2899  data_time: 0.0043  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 14:59:32 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 1859  total_loss: 1.244  loss_mask: 0.2455  loss_fcos_cls: 0.1864  loss_fcos_loc: 0.1799  loss_fcos_ctr: 0.6184  time: 1.2899  data_time: 0.0055  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 14:59:58 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 1879  total_loss: 1.251  loss_mask: 0.2552  loss_fcos_cls: 0.1825  loss_fcos_loc: 0.1834  loss_fcos_ctr: 0.6194  time: 1.2900  data_time: 0.0053  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 15:00:24 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 1899  total_loss: 1.227  loss_mask: 0.2568  loss_fcos_cls: 0.1562  loss_fcos_loc: 0.1955  loss_fcos_ctr: 0.6223  time: 1.2902  data_time: 0.0046  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 15:00:49 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 1919  total_loss: 1.164  loss_mask: 0.2212  loss_fcos_cls: 0.1287  loss_fcos_loc: 0.1617  loss_fcos_ctr: 0.6157  time: 1.2900  data_time: 0.0048  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 15:01:15 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 1939  total_loss: 1.292  loss_mask: 0.2679  loss_fcos_cls: 0.1634  loss_fcos_loc: 0.1849  loss_fcos_ctr: 0.6209  time: 1.2899  data_time: 0.0057  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 15:01:41 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 1959  total_loss: 1.369  loss_mask: 0.2997  loss_fcos_cls: 0.1905  loss_fcos_loc: 0.2189  loss_fcos_ctr: 0.6315  time: 1.2898  data_time: 0.0049  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 15:02:07 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 1979  total_loss: 1.236  loss_mask: 0.2753  loss_fcos_cls: 0.1679  loss_fcos_loc: 0.2078  loss_fcos_ctr: 0.6206  time: 1.2899  data_time: 0.0058  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 15:02:33 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1999  total_loss: 1.259  loss_mask: 0.2551  loss_fcos_cls: 0.1443  loss_fcos_loc: 0.1819  loss_fcos_ctr: 0.6212  time: 1.2898  data_time: 0.0056  lr: 0.0001  max_mem: 2128M\n","\u001b[32m[02/06 15:02:33 d2.engine.hooks]: \u001b[0mOverall training speed: 1998 iterations in 0:42:56 (1.2898 s / it)\n","\u001b[32m[02/06 15:02:33 d2.engine.hooks]: \u001b[0mTotal training time: 0:43:01 (0:00:04 on hooks)\n"]}]},{"cell_type":"code","source":["cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n","predictor = DefaultPredictor(cfg)"],"metadata":{"id":"DdSdKpqYNezF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","from detectron2.data import build_detection_test_loader\n","evaluator = COCOEvaluator(\"cityscapes_val\", cfg, False, output_dir=\"./output\")\n","val_loader = build_detection_test_loader(cfg, \"cityscapes_val\")\n","print(inference_on_dataset(predictor.model, val_loader, evaluator))"],"metadata":{"id":"HCxlhN-zNnWj","executionInfo":{"status":"ok","timestamp":1644160637529,"user_tz":-60,"elapsed":881931,"user":{"displayName":"muchsb 2021","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioRvCcJyMu2pLImQLAH9SrtPIxQR-65c4Rc0Lq=s64","userId":"04872446583146860130"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"77ab3acb-fcee-46b2-a211-4e9c7305865c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/06 15:02:35 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","\u001b[32m[02/06 15:02:35 d2.evaluation.coco_evaluation]: \u001b[0mTrying to convert 'cityscapes_val' to COCO format ...\n","\u001b[32m[02/06 15:02:35 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'cityscapes_val' to COCO format ...)\n","\u001b[32m[02/06 15:03:50 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n","\u001b[32m[02/06 15:03:53 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 500, #annotations: 10657\n","\u001b[32m[02/06 15:03:53 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './output/cityscapes_val_coco_format.json' ...\n","\u001b[32m[02/06 15:04:55 d2.data.build]: \u001b[0mDistribution of instances among all 8 categories:\n","\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n","|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n","|   person   | 3400         |   rider    | 544          |    car     | 4657         |\n","|   truck    | 93           |    bus     | 98           |   train    | 23           |\n","| motorcycle | 149          |  bicycle   | 1169         |            |              |\n","|   total    | 10133        |            |              |            |              |\u001b[0m\n","\u001b[32m[02/06 15:04:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[02/06 15:04:55 d2.data.common]: \u001b[0mSerializing 500 elements to byte tensors and concatenating them all ...\n","\u001b[32m[02/06 15:04:55 d2.data.common]: \u001b[0mSerialized dataset takes 12.86 MiB\n","\u001b[32m[02/06 15:04:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 500 batches\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  max_size = (max_size + (stride - 1)) // stride * stride\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32m[02/06 15:05:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/500. Dataloading: 0.0012 s/iter. Inference: 0.6692 s/iter. Eval: 0.8641 s/iter. Total: 1.5345 s/iter. ETA=0:12:30\n","\u001b[32m[02/06 15:05:19 d2.evaluation.evaluator]: \u001b[0mInference done 15/500. Dataloading: 0.0018 s/iter. Inference: 0.6656 s/iter. Eval: 0.8499 s/iter. Total: 1.5175 s/iter. ETA=0:12:15\n","\u001b[32m[02/06 15:05:25 d2.evaluation.evaluator]: \u001b[0mInference done 19/500. Dataloading: 0.0018 s/iter. Inference: 0.6655 s/iter. Eval: 0.8540 s/iter. Total: 1.5216 s/iter. ETA=0:12:11\n","\u001b[32m[02/06 15:05:31 d2.evaluation.evaluator]: \u001b[0mInference done 23/500. Dataloading: 0.0021 s/iter. Inference: 0.6634 s/iter. Eval: 0.8462 s/iter. Total: 1.5121 s/iter. ETA=0:12:01\n","\u001b[32m[02/06 15:05:37 d2.evaluation.evaluator]: \u001b[0mInference done 27/500. Dataloading: 0.0023 s/iter. Inference: 0.6641 s/iter. Eval: 0.8512 s/iter. Total: 1.5180 s/iter. ETA=0:11:58\n","\u001b[32m[02/06 15:05:44 d2.evaluation.evaluator]: \u001b[0mInference done 31/500. Dataloading: 0.0025 s/iter. Inference: 0.6651 s/iter. Eval: 0.8529 s/iter. Total: 1.5209 s/iter. ETA=0:11:53\n","\u001b[32m[02/06 15:05:49 d2.evaluation.evaluator]: \u001b[0mInference done 35/500. Dataloading: 0.0025 s/iter. Inference: 0.6650 s/iter. Eval: 0.8464 s/iter. Total: 1.5144 s/iter. ETA=0:11:44\n","\u001b[32m[02/06 15:05:56 d2.evaluation.evaluator]: \u001b[0mInference done 39/500. Dataloading: 0.0025 s/iter. Inference: 0.6652 s/iter. Eval: 0.8465 s/iter. Total: 1.5148 s/iter. ETA=0:11:38\n","\u001b[32m[02/06 15:06:02 d2.evaluation.evaluator]: \u001b[0mInference done 43/500. Dataloading: 0.0026 s/iter. Inference: 0.6654 s/iter. Eval: 0.8551 s/iter. Total: 1.5236 s/iter. ETA=0:11:36\n","\u001b[32m[02/06 15:06:08 d2.evaluation.evaluator]: \u001b[0mInference done 47/500. Dataloading: 0.0027 s/iter. Inference: 0.6659 s/iter. Eval: 0.8547 s/iter. Total: 1.5238 s/iter. ETA=0:11:30\n","\u001b[32m[02/06 15:06:14 d2.evaluation.evaluator]: \u001b[0mInference done 51/500. Dataloading: 0.0027 s/iter. Inference: 0.6651 s/iter. Eval: 0.8518 s/iter. Total: 1.5201 s/iter. ETA=0:11:22\n","\u001b[32m[02/06 15:06:20 d2.evaluation.evaluator]: \u001b[0mInference done 55/500. Dataloading: 0.0027 s/iter. Inference: 0.6658 s/iter. Eval: 0.8516 s/iter. Total: 1.5206 s/iter. ETA=0:11:16\n","\u001b[32m[02/06 15:06:26 d2.evaluation.evaluator]: \u001b[0mInference done 59/500. Dataloading: 0.0027 s/iter. Inference: 0.6662 s/iter. Eval: 0.8510 s/iter. Total: 1.5205 s/iter. ETA=0:11:10\n","\u001b[32m[02/06 15:06:32 d2.evaluation.evaluator]: \u001b[0mInference done 63/500. Dataloading: 0.0028 s/iter. Inference: 0.6663 s/iter. Eval: 0.8517 s/iter. Total: 1.5213 s/iter. ETA=0:11:04\n","\u001b[32m[02/06 15:06:38 d2.evaluation.evaluator]: \u001b[0mInference done 67/500. Dataloading: 0.0028 s/iter. Inference: 0.6660 s/iter. Eval: 0.8506 s/iter. Total: 1.5198 s/iter. ETA=0:10:58\n","\u001b[32m[02/06 15:06:44 d2.evaluation.evaluator]: \u001b[0mInference done 71/500. Dataloading: 0.0028 s/iter. Inference: 0.6662 s/iter. Eval: 0.8511 s/iter. Total: 1.5206 s/iter. ETA=0:10:52\n","\u001b[32m[02/06 15:06:50 d2.evaluation.evaluator]: \u001b[0mInference done 75/500. Dataloading: 0.0028 s/iter. Inference: 0.6663 s/iter. Eval: 0.8500 s/iter. Total: 1.5197 s/iter. ETA=0:10:45\n","\u001b[32m[02/06 15:06:57 d2.evaluation.evaluator]: \u001b[0mInference done 79/500. Dataloading: 0.0029 s/iter. Inference: 0.6667 s/iter. Eval: 0.8503 s/iter. Total: 1.5204 s/iter. ETA=0:10:40\n","\u001b[32m[02/06 15:07:03 d2.evaluation.evaluator]: \u001b[0mInference done 83/500. Dataloading: 0.0029 s/iter. Inference: 0.6669 s/iter. Eval: 0.8502 s/iter. Total: 1.5205 s/iter. ETA=0:10:34\n","\u001b[32m[02/06 15:07:09 d2.evaluation.evaluator]: \u001b[0mInference done 87/500. Dataloading: 0.0029 s/iter. Inference: 0.6671 s/iter. Eval: 0.8504 s/iter. Total: 1.5209 s/iter. ETA=0:10:28\n","\u001b[32m[02/06 15:07:15 d2.evaluation.evaluator]: \u001b[0mInference done 91/500. Dataloading: 0.0029 s/iter. Inference: 0.6673 s/iter. Eval: 0.8506 s/iter. Total: 1.5214 s/iter. ETA=0:10:22\n","\u001b[32m[02/06 15:07:21 d2.evaluation.evaluator]: \u001b[0mInference done 95/500. Dataloading: 0.0030 s/iter. Inference: 0.6676 s/iter. Eval: 0.8509 s/iter. Total: 1.5221 s/iter. ETA=0:10:16\n","\u001b[32m[02/06 15:07:27 d2.evaluation.evaluator]: \u001b[0mInference done 99/500. Dataloading: 0.0030 s/iter. Inference: 0.6677 s/iter. Eval: 0.8505 s/iter. Total: 1.5218 s/iter. ETA=0:10:10\n","\u001b[32m[02/06 15:07:33 d2.evaluation.evaluator]: \u001b[0mInference done 103/500. Dataloading: 0.0030 s/iter. Inference: 0.6671 s/iter. Eval: 0.8472 s/iter. Total: 1.5179 s/iter. ETA=0:10:02\n","\u001b[32m[02/06 15:07:39 d2.evaluation.evaluator]: \u001b[0mInference done 107/500. Dataloading: 0.0030 s/iter. Inference: 0.6669 s/iter. Eval: 0.8462 s/iter. Total: 1.5167 s/iter. ETA=0:09:56\n","\u001b[32m[02/06 15:07:45 d2.evaluation.evaluator]: \u001b[0mInference done 111/500. Dataloading: 0.0030 s/iter. Inference: 0.6670 s/iter. Eval: 0.8465 s/iter. Total: 1.5171 s/iter. ETA=0:09:50\n","\u001b[32m[02/06 15:07:51 d2.evaluation.evaluator]: \u001b[0mInference done 115/500. Dataloading: 0.0030 s/iter. Inference: 0.6667 s/iter. Eval: 0.8469 s/iter. Total: 1.5172 s/iter. ETA=0:09:44\n","\u001b[32m[02/06 15:07:57 d2.evaluation.evaluator]: \u001b[0mInference done 119/500. Dataloading: 0.0029 s/iter. Inference: 0.6668 s/iter. Eval: 0.8460 s/iter. Total: 1.5164 s/iter. ETA=0:09:37\n","\u001b[32m[02/06 15:08:03 d2.evaluation.evaluator]: \u001b[0mInference done 124/500. Dataloading: 0.0030 s/iter. Inference: 0.6649 s/iter. Eval: 0.8364 s/iter. Total: 1.5049 s/iter. ETA=0:09:25\n","\u001b[32m[02/06 15:08:09 d2.evaluation.evaluator]: \u001b[0mInference done 128/500. Dataloading: 0.0030 s/iter. Inference: 0.6642 s/iter. Eval: 0.8334 s/iter. Total: 1.5013 s/iter. ETA=0:09:18\n","\u001b[32m[02/06 15:08:14 d2.evaluation.evaluator]: \u001b[0mInference done 132/500. Dataloading: 0.0030 s/iter. Inference: 0.6634 s/iter. Eval: 0.8296 s/iter. Total: 1.4966 s/iter. ETA=0:09:10\n","\u001b[32m[02/06 15:08:20 d2.evaluation.evaluator]: \u001b[0mInference done 136/500. Dataloading: 0.0030 s/iter. Inference: 0.6632 s/iter. Eval: 0.8282 s/iter. Total: 1.4951 s/iter. ETA=0:09:04\n","\u001b[32m[02/06 15:08:26 d2.evaluation.evaluator]: \u001b[0mInference done 140/500. Dataloading: 0.0030 s/iter. Inference: 0.6633 s/iter. Eval: 0.8291 s/iter. Total: 1.4961 s/iter. ETA=0:08:58\n","\u001b[32m[02/06 15:08:31 d2.evaluation.evaluator]: \u001b[0mInference done 144/500. Dataloading: 0.0030 s/iter. Inference: 0.6627 s/iter. Eval: 0.8263 s/iter. Total: 1.4926 s/iter. ETA=0:08:51\n","\u001b[32m[02/06 15:08:37 d2.evaluation.evaluator]: \u001b[0mInference done 148/500. Dataloading: 0.0030 s/iter. Inference: 0.6624 s/iter. Eval: 0.8235 s/iter. Total: 1.4895 s/iter. ETA=0:08:44\n","\u001b[32m[02/06 15:08:43 d2.evaluation.evaluator]: \u001b[0mInference done 152/500. Dataloading: 0.0030 s/iter. Inference: 0.6627 s/iter. Eval: 0.8246 s/iter. Total: 1.4909 s/iter. ETA=0:08:38\n","\u001b[32m[02/06 15:08:49 d2.evaluation.evaluator]: \u001b[0mInference done 156/500. Dataloading: 0.0030 s/iter. Inference: 0.6628 s/iter. Eval: 0.8251 s/iter. Total: 1.4916 s/iter. ETA=0:08:33\n","\u001b[32m[02/06 15:08:55 d2.evaluation.evaluator]: \u001b[0mInference done 160/500. Dataloading: 0.0030 s/iter. Inference: 0.6631 s/iter. Eval: 0.8260 s/iter. Total: 1.4928 s/iter. ETA=0:08:27\n","\u001b[32m[02/06 15:09:02 d2.evaluation.evaluator]: \u001b[0mInference done 164/500. Dataloading: 0.0030 s/iter. Inference: 0.6631 s/iter. Eval: 0.8268 s/iter. Total: 1.4936 s/iter. ETA=0:08:21\n","\u001b[32m[02/06 15:09:07 d2.evaluation.evaluator]: \u001b[0mInference done 168/500. Dataloading: 0.0030 s/iter. Inference: 0.6631 s/iter. Eval: 0.8261 s/iter. Total: 1.4929 s/iter. ETA=0:08:15\n","\u001b[32m[02/06 15:09:13 d2.evaluation.evaluator]: \u001b[0mInference done 172/500. Dataloading: 0.0030 s/iter. Inference: 0.6632 s/iter. Eval: 0.8269 s/iter. Total: 1.4937 s/iter. ETA=0:08:09\n","\u001b[32m[02/06 15:09:19 d2.evaluation.evaluator]: \u001b[0mInference done 177/500. Dataloading: 0.0030 s/iter. Inference: 0.6617 s/iter. Eval: 0.8188 s/iter. Total: 1.4841 s/iter. ETA=0:07:59\n","\u001b[32m[02/06 15:09:25 d2.evaluation.evaluator]: \u001b[0mInference done 183/500. Dataloading: 0.0030 s/iter. Inference: 0.6590 s/iter. Eval: 0.8060 s/iter. Total: 1.4686 s/iter. ETA=0:07:45\n","\u001b[32m[02/06 15:09:31 d2.evaluation.evaluator]: \u001b[0mInference done 188/500. Dataloading: 0.0030 s/iter. Inference: 0.6568 s/iter. Eval: 0.7959 s/iter. Total: 1.4564 s/iter. ETA=0:07:34\n","\u001b[32m[02/06 15:09:37 d2.evaluation.evaluator]: \u001b[0mInference done 193/500. Dataloading: 0.0030 s/iter. Inference: 0.6556 s/iter. Eval: 0.7912 s/iter. Total: 1.4505 s/iter. ETA=0:07:25\n","\u001b[32m[02/06 15:09:42 d2.evaluation.evaluator]: \u001b[0mInference done 197/500. Dataloading: 0.0030 s/iter. Inference: 0.6550 s/iter. Eval: 0.7903 s/iter. Total: 1.4490 s/iter. ETA=0:07:19\n","\u001b[32m[02/06 15:09:48 d2.evaluation.evaluator]: \u001b[0mInference done 202/500. Dataloading: 0.0030 s/iter. Inference: 0.6538 s/iter. Eval: 0.7838 s/iter. Total: 1.4412 s/iter. ETA=0:07:09\n","\u001b[32m[02/06 15:09:53 d2.evaluation.evaluator]: \u001b[0mInference done 206/500. Dataloading: 0.0030 s/iter. Inference: 0.6532 s/iter. Eval: 0.7815 s/iter. Total: 1.4384 s/iter. ETA=0:07:02\n","\u001b[32m[02/06 15:10:00 d2.evaluation.evaluator]: \u001b[0mInference done 212/500. Dataloading: 0.0030 s/iter. Inference: 0.6515 s/iter. Eval: 0.7725 s/iter. Total: 1.4276 s/iter. ETA=0:06:51\n","\u001b[32m[02/06 15:10:05 d2.evaluation.evaluator]: \u001b[0mInference done 218/500. Dataloading: 0.0030 s/iter. Inference: 0.6488 s/iter. Eval: 0.7585 s/iter. Total: 1.4109 s/iter. ETA=0:06:37\n","\u001b[32m[02/06 15:10:10 d2.evaluation.evaluator]: \u001b[0mInference done 223/500. Dataloading: 0.0030 s/iter. Inference: 0.6474 s/iter. Eval: 0.7537 s/iter. Total: 1.4048 s/iter. ETA=0:06:29\n","\u001b[32m[02/06 15:10:16 d2.evaluation.evaluator]: \u001b[0mInference done 227/500. Dataloading: 0.0030 s/iter. Inference: 0.6469 s/iter. Eval: 0.7528 s/iter. Total: 1.4034 s/iter. ETA=0:06:23\n","\u001b[32m[02/06 15:10:21 d2.evaluation.evaluator]: \u001b[0mInference done 232/500. Dataloading: 0.0030 s/iter. Inference: 0.6459 s/iter. Eval: 0.7483 s/iter. Total: 1.3979 s/iter. ETA=0:06:14\n","\u001b[32m[02/06 15:10:27 d2.evaluation.evaluator]: \u001b[0mInference done 236/500. Dataloading: 0.0031 s/iter. Inference: 0.6459 s/iter. Eval: 0.7483 s/iter. Total: 1.3978 s/iter. ETA=0:06:09\n","\u001b[32m[02/06 15:10:33 d2.evaluation.evaluator]: \u001b[0mInference done 240/500. Dataloading: 0.0030 s/iter. Inference: 0.6460 s/iter. Eval: 0.7486 s/iter. Total: 1.3982 s/iter. ETA=0:06:03\n","\u001b[32m[02/06 15:10:39 d2.evaluation.evaluator]: \u001b[0mInference done 244/500. Dataloading: 0.0030 s/iter. Inference: 0.6463 s/iter. Eval: 0.7502 s/iter. Total: 1.4002 s/iter. ETA=0:05:58\n","\u001b[32m[02/06 15:10:45 d2.evaluation.evaluator]: \u001b[0mInference done 248/500. Dataloading: 0.0030 s/iter. Inference: 0.6466 s/iter. Eval: 0.7522 s/iter. Total: 1.4025 s/iter. ETA=0:05:53\n","\u001b[32m[02/06 15:10:51 d2.evaluation.evaluator]: \u001b[0mInference done 252/500. Dataloading: 0.0030 s/iter. Inference: 0.6470 s/iter. Eval: 0.7542 s/iter. Total: 1.4049 s/iter. ETA=0:05:48\n","\u001b[32m[02/06 15:10:57 d2.evaluation.evaluator]: \u001b[0mInference done 256/500. Dataloading: 0.0030 s/iter. Inference: 0.6473 s/iter. Eval: 0.7559 s/iter. Total: 1.4069 s/iter. ETA=0:05:43\n","\u001b[32m[02/06 15:11:03 d2.evaluation.evaluator]: \u001b[0mInference done 260/500. Dataloading: 0.0030 s/iter. Inference: 0.6476 s/iter. Eval: 0.7567 s/iter. Total: 1.4079 s/iter. ETA=0:05:37\n","\u001b[32m[02/06 15:11:09 d2.evaluation.evaluator]: \u001b[0mInference done 264/500. Dataloading: 0.0031 s/iter. Inference: 0.6477 s/iter. Eval: 0.7577 s/iter. Total: 1.4091 s/iter. ETA=0:05:32\n","\u001b[32m[02/06 15:11:15 d2.evaluation.evaluator]: \u001b[0mInference done 268/500. Dataloading: 0.0031 s/iter. Inference: 0.6480 s/iter. Eval: 0.7595 s/iter. Total: 1.4112 s/iter. ETA=0:05:27\n","\u001b[32m[02/06 15:11:21 d2.evaluation.evaluator]: \u001b[0mInference done 272/500. Dataloading: 0.0031 s/iter. Inference: 0.6482 s/iter. Eval: 0.7608 s/iter. Total: 1.4127 s/iter. ETA=0:05:22\n","\u001b[32m[02/06 15:11:27 d2.evaluation.evaluator]: \u001b[0mInference done 276/500. Dataloading: 0.0031 s/iter. Inference: 0.6485 s/iter. Eval: 0.7625 s/iter. Total: 1.4147 s/iter. ETA=0:05:16\n","\u001b[32m[02/06 15:11:34 d2.evaluation.evaluator]: \u001b[0mInference done 280/500. Dataloading: 0.0031 s/iter. Inference: 0.6489 s/iter. Eval: 0.7642 s/iter. Total: 1.4168 s/iter. ETA=0:05:11\n","\u001b[32m[02/06 15:11:39 d2.evaluation.evaluator]: \u001b[0mInference done 284/500. Dataloading: 0.0031 s/iter. Inference: 0.6488 s/iter. Eval: 0.7638 s/iter. Total: 1.4163 s/iter. ETA=0:05:05\n","\u001b[32m[02/06 15:11:45 d2.evaluation.evaluator]: \u001b[0mInference done 288/500. Dataloading: 0.0031 s/iter. Inference: 0.6492 s/iter. Eval: 0.7653 s/iter. Total: 1.4181 s/iter. ETA=0:05:00\n","\u001b[32m[02/06 15:11:52 d2.evaluation.evaluator]: \u001b[0mInference done 292/500. Dataloading: 0.0031 s/iter. Inference: 0.6494 s/iter. Eval: 0.7667 s/iter. Total: 1.4199 s/iter. ETA=0:04:55\n","\u001b[32m[02/06 15:11:58 d2.evaluation.evaluator]: \u001b[0mInference done 296/500. Dataloading: 0.0031 s/iter. Inference: 0.6497 s/iter. Eval: 0.7685 s/iter. Total: 1.4219 s/iter. ETA=0:04:50\n","\u001b[32m[02/06 15:12:04 d2.evaluation.evaluator]: \u001b[0mInference done 300/500. Dataloading: 0.0031 s/iter. Inference: 0.6500 s/iter. Eval: 0.7700 s/iter. Total: 1.4236 s/iter. ETA=0:04:44\n","\u001b[32m[02/06 15:12:10 d2.evaluation.evaluator]: \u001b[0mInference done 304/500. Dataloading: 0.0031 s/iter. Inference: 0.6502 s/iter. Eval: 0.7712 s/iter. Total: 1.4251 s/iter. ETA=0:04:39\n","\u001b[32m[02/06 15:12:16 d2.evaluation.evaluator]: \u001b[0mInference done 308/500. Dataloading: 0.0031 s/iter. Inference: 0.6503 s/iter. Eval: 0.7714 s/iter. Total: 1.4253 s/iter. ETA=0:04:33\n","\u001b[32m[02/06 15:12:22 d2.evaluation.evaluator]: \u001b[0mInference done 312/500. Dataloading: 0.0031 s/iter. Inference: 0.6505 s/iter. Eval: 0.7725 s/iter. Total: 1.4268 s/iter. ETA=0:04:28\n","\u001b[32m[02/06 15:12:28 d2.evaluation.evaluator]: \u001b[0mInference done 316/500. Dataloading: 0.0030 s/iter. Inference: 0.6508 s/iter. Eval: 0.7737 s/iter. Total: 1.4282 s/iter. ETA=0:04:22\n","\u001b[32m[02/06 15:12:34 d2.evaluation.evaluator]: \u001b[0mInference done 320/500. Dataloading: 0.0031 s/iter. Inference: 0.6510 s/iter. Eval: 0.7751 s/iter. Total: 1.4298 s/iter. ETA=0:04:17\n","\u001b[32m[02/06 15:12:41 d2.evaluation.evaluator]: \u001b[0mInference done 324/500. Dataloading: 0.0030 s/iter. Inference: 0.6513 s/iter. Eval: 0.7762 s/iter. Total: 1.4312 s/iter. ETA=0:04:11\n","\u001b[32m[02/06 15:12:47 d2.evaluation.evaluator]: \u001b[0mInference done 328/500. Dataloading: 0.0030 s/iter. Inference: 0.6515 s/iter. Eval: 0.7774 s/iter. Total: 1.4326 s/iter. ETA=0:04:06\n","\u001b[32m[02/06 15:12:53 d2.evaluation.evaluator]: \u001b[0mInference done 332/500. Dataloading: 0.0031 s/iter. Inference: 0.6518 s/iter. Eval: 0.7786 s/iter. Total: 1.4341 s/iter. ETA=0:04:00\n","\u001b[32m[02/06 15:12:59 d2.evaluation.evaluator]: \u001b[0mInference done 336/500. Dataloading: 0.0031 s/iter. Inference: 0.6520 s/iter. Eval: 0.7796 s/iter. Total: 1.4353 s/iter. ETA=0:03:55\n","\u001b[32m[02/06 15:13:05 d2.evaluation.evaluator]: \u001b[0mInference done 340/500. Dataloading: 0.0031 s/iter. Inference: 0.6523 s/iter. Eval: 0.7806 s/iter. Total: 1.4366 s/iter. ETA=0:03:49\n","\u001b[32m[02/06 15:13:11 d2.evaluation.evaluator]: \u001b[0mInference done 344/500. Dataloading: 0.0031 s/iter. Inference: 0.6525 s/iter. Eval: 0.7817 s/iter. Total: 1.4379 s/iter. ETA=0:03:44\n","\u001b[32m[02/06 15:13:18 d2.evaluation.evaluator]: \u001b[0mInference done 348/500. Dataloading: 0.0031 s/iter. Inference: 0.6528 s/iter. Eval: 0.7829 s/iter. Total: 1.4393 s/iter. ETA=0:03:38\n","\u001b[32m[02/06 15:13:24 d2.evaluation.evaluator]: \u001b[0mInference done 352/500. Dataloading: 0.0031 s/iter. Inference: 0.6529 s/iter. Eval: 0.7835 s/iter. Total: 1.4400 s/iter. ETA=0:03:33\n","\u001b[32m[02/06 15:13:30 d2.evaluation.evaluator]: \u001b[0mInference done 356/500. Dataloading: 0.0031 s/iter. Inference: 0.6529 s/iter. Eval: 0.7837 s/iter. Total: 1.4404 s/iter. ETA=0:03:27\n","\u001b[32m[02/06 15:13:36 d2.evaluation.evaluator]: \u001b[0mInference done 360/500. Dataloading: 0.0031 s/iter. Inference: 0.6532 s/iter. Eval: 0.7848 s/iter. Total: 1.4417 s/iter. ETA=0:03:21\n","\u001b[32m[02/06 15:13:42 d2.evaluation.evaluator]: \u001b[0mInference done 364/500. Dataloading: 0.0030 s/iter. Inference: 0.6533 s/iter. Eval: 0.7858 s/iter. Total: 1.4428 s/iter. ETA=0:03:16\n","\u001b[32m[02/06 15:13:48 d2.evaluation.evaluator]: \u001b[0mInference done 368/500. Dataloading: 0.0030 s/iter. Inference: 0.6535 s/iter. Eval: 0.7868 s/iter. Total: 1.4440 s/iter. ETA=0:03:10\n","\u001b[32m[02/06 15:13:54 d2.evaluation.evaluator]: \u001b[0mInference done 372/500. Dataloading: 0.0030 s/iter. Inference: 0.6536 s/iter. Eval: 0.7879 s/iter. Total: 1.4452 s/iter. ETA=0:03:04\n","\u001b[32m[02/06 15:14:00 d2.evaluation.evaluator]: \u001b[0mInference done 376/500. Dataloading: 0.0030 s/iter. Inference: 0.6544 s/iter. Eval: 0.7879 s/iter. Total: 1.4460 s/iter. ETA=0:02:59\n","\u001b[32m[02/06 15:14:07 d2.evaluation.evaluator]: \u001b[0mInference done 380/500. Dataloading: 0.0031 s/iter. Inference: 0.6545 s/iter. Eval: 0.7889 s/iter. Total: 1.4472 s/iter. ETA=0:02:53\n","\u001b[32m[02/06 15:14:13 d2.evaluation.evaluator]: \u001b[0mInference done 384/500. Dataloading: 0.0031 s/iter. Inference: 0.6546 s/iter. Eval: 0.7894 s/iter. Total: 1.4476 s/iter. ETA=0:02:47\n","\u001b[32m[02/06 15:14:19 d2.evaluation.evaluator]: \u001b[0mInference done 388/500. Dataloading: 0.0030 s/iter. Inference: 0.6546 s/iter. Eval: 0.7901 s/iter. Total: 1.4485 s/iter. ETA=0:02:42\n","\u001b[32m[02/06 15:14:25 d2.evaluation.evaluator]: \u001b[0mInference done 392/500. Dataloading: 0.0030 s/iter. Inference: 0.6548 s/iter. Eval: 0.7902 s/iter. Total: 1.4487 s/iter. ETA=0:02:36\n","\u001b[32m[02/06 15:14:30 d2.evaluation.evaluator]: \u001b[0mInference done 396/500. Dataloading: 0.0031 s/iter. Inference: 0.6546 s/iter. Eval: 0.7894 s/iter. Total: 1.4477 s/iter. ETA=0:02:30\n","\u001b[32m[02/06 15:14:36 d2.evaluation.evaluator]: \u001b[0mInference done 400/500. Dataloading: 0.0030 s/iter. Inference: 0.6548 s/iter. Eval: 0.7903 s/iter. Total: 1.4487 s/iter. ETA=0:02:24\n","\u001b[32m[02/06 15:14:42 d2.evaluation.evaluator]: \u001b[0mInference done 404/500. Dataloading: 0.0030 s/iter. Inference: 0.6549 s/iter. Eval: 0.7909 s/iter. Total: 1.4496 s/iter. ETA=0:02:19\n","\u001b[32m[02/06 15:14:49 d2.evaluation.evaluator]: \u001b[0mInference done 408/500. Dataloading: 0.0030 s/iter. Inference: 0.6551 s/iter. Eval: 0.7916 s/iter. Total: 1.4504 s/iter. ETA=0:02:13\n","\u001b[32m[02/06 15:14:55 d2.evaluation.evaluator]: \u001b[0mInference done 412/500. Dataloading: 0.0030 s/iter. Inference: 0.6552 s/iter. Eval: 0.7924 s/iter. Total: 1.4512 s/iter. ETA=0:02:07\n","\u001b[32m[02/06 15:15:01 d2.evaluation.evaluator]: \u001b[0mInference done 416/500. Dataloading: 0.0030 s/iter. Inference: 0.6553 s/iter. Eval: 0.7932 s/iter. Total: 1.4522 s/iter. ETA=0:02:01\n","\u001b[32m[02/06 15:15:06 d2.evaluation.evaluator]: \u001b[0mInference done 420/500. Dataloading: 0.0030 s/iter. Inference: 0.6552 s/iter. Eval: 0.7924 s/iter. Total: 1.4513 s/iter. ETA=0:01:56\n","\u001b[32m[02/06 15:15:12 d2.evaluation.evaluator]: \u001b[0mInference done 424/500. Dataloading: 0.0030 s/iter. Inference: 0.6553 s/iter. Eval: 0.7931 s/iter. Total: 1.4521 s/iter. ETA=0:01:50\n","\u001b[32m[02/06 15:15:19 d2.evaluation.evaluator]: \u001b[0mInference done 428/500. Dataloading: 0.0030 s/iter. Inference: 0.6555 s/iter. Eval: 0.7937 s/iter. Total: 1.4529 s/iter. ETA=0:01:44\n","\u001b[32m[02/06 15:15:25 d2.evaluation.evaluator]: \u001b[0mInference done 432/500. Dataloading: 0.0030 s/iter. Inference: 0.6556 s/iter. Eval: 0.7943 s/iter. Total: 1.4535 s/iter. ETA=0:01:38\n","\u001b[32m[02/06 15:15:31 d2.evaluation.evaluator]: \u001b[0mInference done 436/500. Dataloading: 0.0030 s/iter. Inference: 0.6557 s/iter. Eval: 0.7950 s/iter. Total: 1.4544 s/iter. ETA=0:01:33\n","\u001b[32m[02/06 15:15:37 d2.evaluation.evaluator]: \u001b[0mInference done 440/500. Dataloading: 0.0030 s/iter. Inference: 0.6559 s/iter. Eval: 0.7958 s/iter. Total: 1.4553 s/iter. ETA=0:01:27\n","\u001b[32m[02/06 15:15:43 d2.evaluation.evaluator]: \u001b[0mInference done 444/500. Dataloading: 0.0030 s/iter. Inference: 0.6560 s/iter. Eval: 0.7964 s/iter. Total: 1.4561 s/iter. ETA=0:01:21\n","\u001b[32m[02/06 15:15:49 d2.evaluation.evaluator]: \u001b[0mInference done 448/500. Dataloading: 0.0030 s/iter. Inference: 0.6560 s/iter. Eval: 0.7969 s/iter. Total: 1.4566 s/iter. ETA=0:01:15\n","\u001b[32m[02/06 15:15:55 d2.evaluation.evaluator]: \u001b[0mInference done 452/500. Dataloading: 0.0030 s/iter. Inference: 0.6562 s/iter. Eval: 0.7976 s/iter. Total: 1.4574 s/iter. ETA=0:01:09\n","\u001b[32m[02/06 15:16:02 d2.evaluation.evaluator]: \u001b[0mInference done 456/500. Dataloading: 0.0030 s/iter. Inference: 0.6563 s/iter. Eval: 0.7982 s/iter. Total: 1.4581 s/iter. ETA=0:01:04\n","\u001b[32m[02/06 15:16:08 d2.evaluation.evaluator]: \u001b[0mInference done 460/500. Dataloading: 0.0030 s/iter. Inference: 0.6564 s/iter. Eval: 0.7989 s/iter. Total: 1.4589 s/iter. ETA=0:00:58\n","\u001b[32m[02/06 15:16:13 d2.evaluation.evaluator]: \u001b[0mInference done 464/500. Dataloading: 0.0030 s/iter. Inference: 0.6563 s/iter. Eval: 0.7985 s/iter. Total: 1.4584 s/iter. ETA=0:00:52\n","\u001b[32m[02/06 15:16:20 d2.evaluation.evaluator]: \u001b[0mInference done 468/500. Dataloading: 0.0030 s/iter. Inference: 0.6565 s/iter. Eval: 0.7991 s/iter. Total: 1.4592 s/iter. ETA=0:00:46\n","\u001b[32m[02/06 15:16:26 d2.evaluation.evaluator]: \u001b[0mInference done 472/500. Dataloading: 0.0030 s/iter. Inference: 0.6566 s/iter. Eval: 0.7996 s/iter. Total: 1.4599 s/iter. ETA=0:00:40\n","\u001b[32m[02/06 15:16:32 d2.evaluation.evaluator]: \u001b[0mInference done 476/500. Dataloading: 0.0030 s/iter. Inference: 0.6567 s/iter. Eval: 0.8001 s/iter. Total: 1.4604 s/iter. ETA=0:00:35\n","\u001b[32m[02/06 15:16:38 d2.evaluation.evaluator]: \u001b[0mInference done 480/500. Dataloading: 0.0030 s/iter. Inference: 0.6568 s/iter. Eval: 0.8007 s/iter. Total: 1.4611 s/iter. ETA=0:00:29\n","\u001b[32m[02/06 15:16:44 d2.evaluation.evaluator]: \u001b[0mInference done 484/500. Dataloading: 0.0030 s/iter. Inference: 0.6569 s/iter. Eval: 0.8013 s/iter. Total: 1.4618 s/iter. ETA=0:00:23\n","\u001b[32m[02/06 15:16:50 d2.evaluation.evaluator]: \u001b[0mInference done 488/500. Dataloading: 0.0030 s/iter. Inference: 0.6570 s/iter. Eval: 0.8015 s/iter. Total: 1.4622 s/iter. ETA=0:00:17\n","\u001b[32m[02/06 15:16:56 d2.evaluation.evaluator]: \u001b[0mInference done 492/500. Dataloading: 0.0030 s/iter. Inference: 0.6571 s/iter. Eval: 0.8021 s/iter. Total: 1.4629 s/iter. ETA=0:00:11\n","\u001b[32m[02/06 15:17:03 d2.evaluation.evaluator]: \u001b[0mInference done 496/500. Dataloading: 0.0030 s/iter. Inference: 0.6572 s/iter. Eval: 0.8026 s/iter. Total: 1.4635 s/iter. ETA=0:00:05\n","\u001b[32m[02/06 15:17:09 d2.evaluation.evaluator]: \u001b[0mInference done 500/500. Dataloading: 0.0030 s/iter. Inference: 0.6573 s/iter. Eval: 0.8031 s/iter. Total: 1.4640 s/iter. ETA=0:00:00\n","\u001b[32m[02/06 15:17:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:12:04.818354 (1.464280 s / iter per device, on 1 devices)\n","\u001b[32m[02/06 15:17:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:05:25 (0.657291 s / iter per device, on 1 devices)\n","\u001b[32m[02/06 15:17:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[02/06 15:17:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n","\u001b[32m[02/06 15:17:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.12s)\n","creating index...\n","index created!\n","\u001b[32m[02/06 15:17:10 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n","\u001b[32m[02/06 15:17:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.97 seconds.\n","\u001b[32m[02/06 15:17:11 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[02/06 15:17:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.15 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.448\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.294\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.088\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.551\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.222\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.407\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.439\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.111\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.455\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.729\n","\u001b[32m[02/06 15:17:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n","|:------:|:------:|:------:|:-----:|:------:|:------:|\n","| 28.846 | 44.788 | 29.405 | 8.827 | 31.560 | 55.150 |\n","\u001b[32m[02/06 15:17:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n","| category   | AP     | category   | AP     | category   | AP     |\n","|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n","| person     | 32.941 | rider      | 30.643 | car        | 51.210 |\n","| truck      | 28.102 | bus        | 41.039 | train      | 2.755  |\n","| motorcycle | 17.290 | bicycle    | 26.789 |            |        |\n","Loading and preparing results...\n","DONE (t=0.69s)\n","creating index...\n","index created!\n","\u001b[32m[02/06 15:17:13 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n","\u001b[32m[02/06 15:17:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 3.02 seconds.\n","\u001b[32m[02/06 15:17:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[02/06 15:17:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.15 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.234\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.400\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.221\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.023\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.213\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.514\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.208\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.370\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.057\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.348\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.677\n","\u001b[32m[02/06 15:17:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n","|:------:|:------:|:------:|:-----:|:------:|:------:|\n","| 23.416 | 39.980 | 22.095 | 2.348 | 21.335 | 51.446 |\n","\u001b[32m[02/06 15:17:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n","| category   | AP     | category   | AP     | category   | AP     |\n","|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n","| person     | 24.970 | rider      | 17.211 | car        | 44.749 |\n","| truck      | 29.266 | bus        | 40.385 | train      | 4.102  |\n","| motorcycle | 11.538 | bicycle    | 15.111 |            |        |\n","OrderedDict([('bbox', {'AP': 28.845974758807635, 'AP50': 44.78815907516727, 'AP75': 29.40450017069283, 'APs': 8.826623718024399, 'APm': 31.559541585956847, 'APl': 55.149782716955066, 'AP-person': 32.94059175812507, 'AP-rider': 30.642687657014527, 'AP-car': 51.21041116755938, 'AP-truck': 28.101905476419436, 'AP-bus': 41.038926315607, 'AP-train': 2.754951802756274, 'AP-motorcycle': 17.289557902402166, 'AP-bicycle': 26.7887659905772}), ('segm', {'AP': 23.416466669749667, 'AP50': 39.98009619401478, 'AP75': 22.094851710810186, 'APs': 2.347703845502309, 'APm': 21.335054313638185, 'APl': 51.44604237760269, 'AP-person': 24.96978013651683, 'AP-rider': 17.21141331937785, 'AP-car': 44.74900566882093, 'AP-truck': 29.26564220718059, 'AP-bus': 40.38475725472729, 'AP-train': 4.101702169435354, 'AP-motorcycle': 11.538024634266796, 'AP-bicycle': 15.111407967671658})])\n"]}]},{"cell_type":"markdown","source":["**Stampa immagini**"],"metadata":{"id":"QiATS8unOAkC"}},{"cell_type":"code","source":["%load_ext tensorboard\n","%tensorboard --logdir output"],"metadata":{"id":"9lD3LbyAN_yk","executionInfo":{"status":"ok","timestamp":1644160648409,"user_tz":-60,"elapsed":10890,"user":{"displayName":"muchsb 2021","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioRvCcJyMu2pLImQLAH9SrtPIxQR-65c4Rc0Lq=s64","userId":"04872446583146860130"}},"colab":{"base_uri":"https://localhost:8080/","height":821},"outputId":"0cea1753-65ab-465b-9609-04f567dc394e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_config = open(\"cfg.yaml\", \"w\")\n","model_config.write(str(cfg))\n","model_config.close()"],"metadata":{"id":"dzWtT-IEUpub"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python demo/demo.py \\\n","    --config-file /content/AdelaiDet/cfg.yaml \\\n","    --input /content/drive/MyDrive/datasets/cityscapes/leftImg8bit/test/bonn/bonn_000013_000019_leftImg8bit.png \\\n","    --confidence-threshold 0.5 \\\n","    --output outBM1.jpg \\\n","    --opts MODEL.WEIGHTS /content/AdelaiDet/output/blendmask/R_101_3x/model_final.pth"],"metadata":{"id":"jGp-_f_iUqBO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644160881744,"user_tz":-60,"elapsed":8956,"user":{"displayName":"muchsb 2021","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioRvCcJyMu2pLImQLAH9SrtPIxQR-65c4Rc0Lq=s64","userId":"04872446583146860130"}},"outputId":"2bd2691e-15c5-46e5-d38c-bfecb7a41604"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[32m[02/06 15:21:15 detectron2]: \u001b[0mArguments: Namespace(confidence_threshold=0.5, config_file='/content/AdelaiDet/cfg.yaml', input=['/content/drive/MyDrive/datasets/cityscapes/leftImg8bit/test/bonn/bonn_000013_000019_leftImg8bit.png'], opts=['MODEL.WEIGHTS', '/content/AdelaiDet/output/blendmask/R_101_3x/model_final.pth'], output='outBM1.jpg', video_input=None, webcam=False)\n","The checkpoint state_dict contains keys that are not used by the model:\n","  \u001b[35mbackbone.fpn_lateral3.bias\u001b[0m\n","  \u001b[35mbackbone.fpn_output3.bias\u001b[0m\n","  \u001b[35mbackbone.fpn_lateral4.bias\u001b[0m\n","  \u001b[35mbackbone.fpn_output4.bias\u001b[0m\n","  \u001b[35mbackbone.fpn_lateral5.bias\u001b[0m\n","  \u001b[35mbackbone.fpn_output5.bias\u001b[0m\n","  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  max_size = (max_size + (stride - 1)) // stride * stride\n","/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode)\n","\u001b[32m[02/06 15:21:20 detectron2]: \u001b[0m/content/drive/MyDrive/datasets/cityscapes/leftImg8bit/test/bonn/bonn_000013_000019_leftImg8bit.png: detected 3 instances in 0.79s\n","100% 1/1 [00:01<00:00,  1.38s/it]\n"]}]},{"cell_type":"code","source":["out1 = cv2.imread(\"outBM1.jpg\")\n","cv2_imshow(out1)"],"metadata":{"id":"ySbJ_Gi6Uuk6","colab":{"base_uri":"https://localhost:8080/","height":446},"executionInfo":{"status":"ok","timestamp":1644160889454,"user_tz":-60,"elapsed":2365,"user":{"displayName":"muchsb 2021","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioRvCcJyMu2pLImQLAH9SrtPIxQR-65c4Rc0Lq=s64","userId":"04872446583146860130"}},"outputId":"31143c46-9a45-4a9a-8e95-53760f006144"},"execution_count":null,"outputs":[]}]}